{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "ANALYSIS_POSTFIX = \"mined_sudden_2024-08-26\"\n",
    "\n",
    "experiment_config = {\n",
    "    \"RS\" : 42,\n",
    "    \"ANALYSIS_POSTFIX\": ANALYSIS_POSTFIX\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_two(experiment_config, \n",
    "             X_train,\n",
    "             y_train,\n",
    "             model,\n",
    "             X_val=None,\n",
    "             y_val=None,\n",
    "             save=False): \n",
    "    \n",
    "    ANALYSIS_POSTFIX = experiment_config[\"ANALYSIS_POSTFIX\"]\n",
    "    \n",
    "    training_start_time = time.time()\n",
    "    if model==\"lr\":\n",
    "        reg = LinearRegression().fit(X_train, y_train)\n",
    "    elif model ==\"svm\": \n",
    "        reg = SVR().fit(X_train, y_train)\n",
    "    elif model==\"rf\":\n",
    "        reg = RandomForestRegressor.fit(X_train, y_train)\n",
    "    elif model==\"lgbm\":\n",
    "        reg = LGBMRegressor(max_depth=10, silent=True)\n",
    "        reg.fit(X=X_train, y=y_train)\n",
    "    elif model==\"catboost\":\n",
    "        reg = CatBoostRegressor()\n",
    "        reg.fit(X=X_train, y=y_train)\n",
    "    training_end_time = time.time()\n",
    "    time_training = training_end_time - training_start_time\n",
    "\n",
    "    \n",
    "\n",
    "    if save:\n",
    "        with open(f'./models/reg_{model}_{ANALYSIS_POSTFIX}.pkl','wb') as f:\n",
    "            pickle.dump(reg, f)\n",
    "        return f'./models/reg_{model}_{ANALYSIS_POSTFIX}.pkl'\n",
    "    \n",
    "    else:\n",
    "        inference_start_time = time.time()\n",
    "        y_pred = reg.predict(X_val)\n",
    "        inference_end_time = time.time()\n",
    "        time_inference = inference_end_time - inference_start_time\n",
    "\n",
    "        y_pred[y_pred<0] = 0\n",
    "        mae = mean_absolute_error(y_true=y_val, y_pred=y_pred)\n",
    "        rmse = math.sqrt(mean_squared_error(y_true=y_val, y_pred=y_pred))\n",
    "        return {\"pred\": y_pred, \"mae\": mae, \"rmse\": rmse, \"time_training\" : time_training, \"time_inference\" : time_inference}\n",
    "    \n",
    "\n",
    "def cv_step_2(experiment_config:dict, cv_df:pd.DataFrame) -> Tuple:\n",
    "\n",
    "    t_models = [\"lr\", \"svm\", \"lgbm\", \"catboost\"]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "\n",
    "    for test_fold in range(cv_df.fold.max()+1):\n",
    "        print(test_fold)\n",
    "\n",
    "        # Prepare the input data\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = vectorizer.fit_transform(cv_df.loc[cv_df.fold!=test_fold, \"input_sequence\"])\n",
    "        X_train_column_sparse = pd.get_dummies(cv_df.loc[cv_df.fold!=test_fold, \"model_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "        X_train = hstack([X_train_column_sparse, X_train_tfidf])\n",
    "        y_train = cv_df.loc[cv_df.fold!=test_fold, \"rouge\"]\n",
    "        \n",
    "        X_val_tfidf = vectorizer.transform(cv_df.loc[cv_df.fold==test_fold, \"input_sequence\"])\n",
    "        X_val_column_sparse = pd.get_dummies(cv_df.loc[cv_df.fold==test_fold, \"model_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "        X_val = hstack([X_val_column_sparse, X_val_tfidf])\n",
    "        y_val = cv_df.loc[cv_df.fold==test_fold, \"rouge\"]\n",
    "\n",
    "        results[test_fold] = {}\n",
    "        for model in t_models:\n",
    "            print(model)\n",
    "            preds_df = step_two(experiment_config=experiment_config,\n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                X_val=X_val,\n",
    "                                y_val=y_val,\n",
    "                                model=model)\n",
    "            cv_df.loc[cv_df.fold==test_fold, f\"{model}_perf_hat\"] = preds_df[\"pred\"]\n",
    "            results[test_fold][model] = preds_df\n",
    "\n",
    "    cv_df = cv_df.reset_index(drop=True)\n",
    "\n",
    "    # rearrange results\n",
    "    model_results = {}\n",
    "\n",
    "    for model in t_models:\n",
    "        model_results[model]= {}\n",
    "        model_results[model][\"rmse\"] = []\n",
    "        model_results[model][\"mae\"] = [] \n",
    "\n",
    "        for fold in range(3):\n",
    "        \n",
    "            model_results[model][\"mae\"].append(results[fold][model][\"mae\"])\n",
    "            model_results[model][\"rmse\"].append(results[fold][model][\"rmse\"])\n",
    "        \n",
    "        model_results[model][\"rmse_avg\"] = np.array(model_results[model][\"rmse\"]).mean()\n",
    "        model_results[model][\"mae_avg\"] = np.array(model_results[model][\"mae\"]).mean()\n",
    "\n",
    "        model_results[model][\"rmse_std\"] = np.array(model_results[model][\"rmse\"]).std()\n",
    "        model_results[model][\"mae_std\"] = np.array(model_results[model][\"mae\"]).std()\n",
    "\n",
    "    for model in t_models:\n",
    "        print(model)\n",
    "        print(\"RMSE \", model_results[model][\"rmse_avg\"])\n",
    "        print(\"MAE \",model_results[model][\"mae_avg\"])\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"RMSE STD \", model_results[model][\"rmse_std\"])\n",
    "        print(\"MAE STD\",model_results[model][\"mae_std\"])\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return cv_df, model_results\n",
    "\n",
    "def full_step_2(cv_df:pd.DataFrame,\n",
    "                experiment_config:dict) -> None:\n",
    "    \n",
    "    ANALYSIS_POSTFIX = experiment_config[\"ANALYSIS_POSTFIX\"]\n",
    "    # TRAIN ON ALL PREDICTIONS AT ONCE\n",
    "\n",
    "    t_models = [\"lr\", \"svm\", \"lgbm\", \"catboost\"]\n",
    "\n",
    "    # Prepare the input data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer.fit_transform(cv_df.loc[cv_df.model_set!=\"ensemble\", \"input_sequence\"])\n",
    "    X_train_column_sparse = pd.get_dummies(cv_df.loc[cv_df.model_set!=\"ensemble\", \"model_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "    X_train = hstack([X_train_column_sparse, X_train_tfidf])\n",
    "    y_train = cv_df.loc[cv_df.model_set!=\"ensemble\", \"rouge\"]\n",
    "        \n",
    "    with open(f\"./models/vectorizer_{ANALYSIS_POSTFIX}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(vectorizer, file, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "        \n",
    "    for model in t_models:\n",
    "        print(model)\n",
    "        preds_df = step_two(experiment_config=experiment_config,\n",
    "                            X_train=X_train,\n",
    "                            y_train=y_train,\n",
    "                            model=model,\n",
    "                            save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../ensemble_learning/reports/results/{ANALYSIS_POSTFIX}/cv_results.pickle\", \"rb\") as handle:\n",
    "    cv_predictions = pickle.load(handle)\n",
    "\n",
    "with open(f\"../ensemble_learning/reports/results/{ANALYSIS_POSTFIX}/test_results.pickle\", \"rb\") as handle:\n",
    "    test_predictions = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TEST = ['question_id', 'parent_answer_post_id', 'prob', 'input_sequence',\n",
    "       'output_sequence', 'id', 'snippet_len', 'intent_len', 'snippet_token_n',\n",
    "       'intent_token_n', 'cluster', 'input_ids', 'attention_mask', 'labels',\n",
    "       'prediction', 'rouge', 'model_set']\n",
    "\n",
    "COLUMNS_CV = COLUMNS_TEST.copy()\n",
    "COLUMNS_CV.append(\"fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predictions = cv_predictions.loc[cv_predictions.model_set!=\"ensemble\", COLUMNS_CV]\n",
    "test_predictions = test_predictions.loc[cv_predictions.model_set!=\"ensemble\", COLUMNS_TEST]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9 base lerner settings models that we compare learning of 1, splitting to two meta models,  all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [0, 1, 2, 5, 10, 'cluster_[1]', 'cluster_[4]', 'cluster_[3]', 'cluster_[0, 1, 4]']\n",
    "MODE = [\"ONE-BY-ONE\", \"TWO-MODELS\", \"ALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_base in MODELS_LIST:\n",
    "\n",
    "    temp_df =  cv_predictions.loc[cv_predictions.model_set==model_base]\n",
    "    temp_df, model_results = cv_step_2(experiment_config=experiment_config,\n",
    "              cv_df=temp_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "\n",
    "t_models = [\"lr\", \"svm\", \"lgbm\", \"catboost\"]\n",
    "\n",
    "for model in t_models:\n",
    "    for cluster in sorted(temp_df.cluster.unique()):\n",
    "\n",
    "        print(cluster)\n",
    "        cluster_temp_df = temp_df.loc[temp_df.cluster==cluster, :]\n",
    "\n",
    "        folds_mae, folds_rmse = [], []\n",
    "        \n",
    "        for fold in range(3):\n",
    "            mae = mean_absolute_error(y_true=cluster_temp_df.loc[cluster_temp_df.fold==fold, \"rouge\"],\n",
    "                                      y_pred=cluster_temp_df.loc[cluster_temp_df.fold==fold, f\"{model}_perf_hat\"])\n",
    "            folds_mae.append(mae)\n",
    "            \n",
    "            rmse = math.sqrt(mean_squared_error(y_true=cluster_temp_df.loc[cluster_temp_df.fold==fold, \"rouge\"],\n",
    "                                      y_pred=cluster_temp_df.loc[cluster_temp_df.fold==fold, f\"{model}_perf_hat\"]))\n",
    "            folds_rmse.append(rmse)\n",
    "\n",
    "        mae = mean_absolute_error(y_true=cluster_temp_df.loc[:, \"rouge\"],\n",
    "                                      y_pred=cluster_temp_df.loc[:, f\"{model}_perf_hat\"])\n",
    "        \n",
    "        rmse = math.sqrt(mean_squared_error(y_true=cluster_temp_df.loc[:, \"rouge\"],\n",
    "                                      y_pred=cluster_temp_df.loc[:, f\"{model}_perf_hat\"]))\n",
    "        \n",
    "        t_res = pd.DataFrame(data={\"model_meta\": model, \"cluster\": cluster, \"rmse_mean\": rmse, \"rmse_std\": np.array(folds_rmse).std(), \"mae_mean\": mae, \"mae_std\": np.array(folds_mae).std()}, index=[0])\n",
    "\n",
    "\n",
    "        results_df = pd.concat([results_df, t_res], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "for model in t_models:\n",
    "\n",
    "    folds_mae, folds_rmse = [], []\n",
    "    \n",
    "    for fold in range(3):\n",
    "        mae = mean_absolute_error(y_true=temp_df.loc[temp_df.fold==fold, \"rouge\"],\n",
    "                                    y_pred=temp_df.loc[temp_df.fold==fold, f\"{model}_perf_hat\"])\n",
    "        folds_mae.append(mae)\n",
    "        \n",
    "        rmse = math.sqrt(mean_squared_error(y_true=temp_df.loc[temp_df.fold==fold, \"rouge\"],\n",
    "                                    y_pred=temp_df.loc[temp_df.fold==fold, f\"{model}_perf_hat\"]))\n",
    "        folds_rmse.append(rmse)\n",
    "\n",
    "    mae = mean_absolute_error(y_true=temp_df.loc[:, \"rouge\"],\n",
    "                                    y_pred=temp_df.loc[:, f\"{model}_perf_hat\"])\n",
    "    \n",
    "    rmse = math.sqrt(mean_squared_error(y_true=temp_df.loc[:, \"rouge\"],\n",
    "                                    y_pred=temp_df.loc[:, f\"{model}_perf_hat\"]))\n",
    "    \n",
    "    t_res = pd.DataFrame(data={\"model_meta\": model, \"cluster\": \"full\", \"rmse_mean\": rmse, \"rmse_std\": np.array(folds_rmse).std(), \"mae_mean\": mae, \"mae_std\": np.array(folds_mae).std()}, index=[0])\n",
    "\n",
    "\n",
    "    results_df = pd.concat([results_df, t_res], axis=0)\n",
    "\n",
    "\n",
    "results_df = results_df.sort_values([\"model_meta\", \"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cluster</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112115</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.094472</td>\n",
       "      <td>0.005743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112536</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.091059</td>\n",
       "      <td>0.011971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.130640</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>3</td>\n",
       "      <td>0.144274</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.114903</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125793</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.101976</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>full</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.107373</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112056</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.092570</td>\n",
       "      <td>0.005152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111786</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.092765</td>\n",
       "      <td>0.007869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.130136</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.104743</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.143615</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.124467</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.101841</td>\n",
       "      <td>0.000636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>full</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.107141</td>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164525</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.112524</td>\n",
       "      <td>0.020246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161518</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.121744</td>\n",
       "      <td>0.004663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>2</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>0.014499</td>\n",
       "      <td>0.138746</td>\n",
       "      <td>0.005807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>3</td>\n",
       "      <td>0.190079</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.140807</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>4</td>\n",
       "      <td>0.159050</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.116850</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>full</td>\n",
       "      <td>0.191686</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.136940</td>\n",
       "      <td>0.004350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112146</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.093473</td>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115481</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.096063</td>\n",
       "      <td>0.010901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133901</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.109732</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.145563</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.116897</td>\n",
       "      <td>0.002689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.105897</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>full</td>\n",
       "      <td>0.136425</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.110917</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model cluster  rmse_mean  rmse_std  mae_mean   mae_std\n",
       "0  catboost       0   0.112115  0.006296  0.094472  0.005743\n",
       "0  catboost       1   0.112536  0.016195  0.091059  0.011971\n",
       "0  catboost       2   0.130640  0.002089  0.105216  0.000883\n",
       "0  catboost       3   0.144274  0.003632  0.114903  0.002323\n",
       "0  catboost       4   0.125793  0.002013  0.101976  0.000844\n",
       "0  catboost    full   0.133906  0.001316  0.107373  0.000185\n",
       "0      lgbm       0   0.112056  0.006191  0.092570  0.005152\n",
       "0      lgbm       1   0.111786  0.010189  0.092765  0.007869\n",
       "0      lgbm       2   0.130136  0.003038  0.104743  0.001400\n",
       "0      lgbm       3   0.143615  0.004118  0.115004  0.003336\n",
       "0      lgbm       4   0.124467  0.001691  0.101841  0.000636\n",
       "0      lgbm    full   0.133311  0.000635  0.107141  0.000708\n",
       "0        lr       0   0.164525  0.032344  0.112524  0.020246\n",
       "0        lr       1   0.161518  0.003853  0.121744  0.004663\n",
       "0        lr       2   0.198251  0.014499  0.138746  0.005807\n",
       "0        lr       3   0.190079  0.006537  0.140807  0.004706\n",
       "0        lr       4   0.159050  0.017202  0.116850  0.008604\n",
       "0        lr    full   0.191686  0.009520  0.136940  0.004350\n",
       "0       svm       0   0.112146  0.002602  0.093473  0.001697\n",
       "0       svm       1   0.115481  0.013498  0.096063  0.010901\n",
       "0       svm       2   0.133901  0.001611  0.109732  0.001131\n",
       "0       svm       3   0.145563  0.004319  0.116897  0.002689\n",
       "0       svm       4   0.129539  0.000955  0.105897  0.002297\n",
       "0       svm    full   0.136425  0.001041  0.110917  0.000367"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
