{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "######### SETTINGS #########\n",
    "############################\n",
    "\n",
    "# Installations\n",
    "#%pip install rouge_score\n",
    "#%pip install absl\n",
    "#%pip install seaborn\n",
    "#%pip install transformers[torch]\n",
    "\n",
    "# Dependencies\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    RobertaTokenizerFast,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import seaborn as sns\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# Constants\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "MODEL = \"CodeT5\"\n",
    "TRAIN_N = 330\n",
    "BATCH_SIZE = 15\n",
    "DECODER_LENGTH = 20\n",
    "ENCODER_LENGTH = 15\n",
    "RS = 42\n",
    "\n",
    "TRAIN_ARGS = {\n",
    "    \"TRAIN_N\": TRAIN_N,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DECODER_LENGTH\": DECODER_LENGTH,\n",
    "    \"ENCODER_LENGTH\": ENCODER_LENGTH,\n",
    "    \"MODEL\": MODEL,\n",
    "    \"SEQ_TRAINER_ARGS\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 10,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 4,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"label_smoothing_factor\": 0.1,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"logging_steps\": 100,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"save_strategy\": \"no\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"load_best_model_at_end\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "model_name=\"Salesforce/codet5-base-multi-sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "######## FUNCTIONS #########\n",
    "############################\n",
    "\n",
    "def prep_for_hf(df: pd.DataFrame) -> Dataset:\n",
    "    \n",
    "    \"\"\"Convert pandas dataframe to huggingface.\"\"\"\n",
    "    \n",
    "    df = df.rename(columns={\"snippet\": \"input_sequence\",  \n",
    "                    \"rewritten_intent\" : \"output_sequence\"})\n",
    "    df = df.loc[:, [\"input_sequence\", \"output_sequence\", \"idx\"]]  \n",
    "    df = df.sample(frac=1, random_state=RS)  \n",
    "    return df, Dataset.from_pandas(df)\n",
    "\n",
    "def batch_tokenize_preprocess(batch, tokenizer, max_input_length, max_output_length):\n",
    "\n",
    "    source = batch[\"input_sequence\"]\n",
    "    target = batch[\"output_sequence\"]\n",
    "\n",
    "    source_tokenized = tokenizer(\n",
    "        source, padding=\"max_length\",\n",
    "        truncation=True, max_length=max_input_length\n",
    "    )\n",
    "\n",
    "    target_tokenized = tokenizer(\n",
    "        target, padding=\"max_length\",\n",
    "        truncation=True, max_length=max_output_length\n",
    "    )\n",
    "\n",
    "    batch = {k: v for k, v in source_tokenized.items()}\n",
    "\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
    "        for label in target_tokenized[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    return batch\n",
    "\n",
    "def generate_summary(test_samples, model, tokenizer, encoder_max_length, decoder_max_length):\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"input_sequence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=decoder_max_length)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "def rouge_custom(prediction, reference): \n",
    "    splitted_reference = reference.lower().split()\n",
    "    matched = sum([word in prediction.lower().split() for word in splitted_reference])\n",
    "    return matched / len(splitted_reference)\n",
    "\n",
    "def bleu_custom(prediction, reference): \n",
    "    splitted_prediction = prediction.lower().split()\n",
    "    matched = sum([word in reference.lower().split() for word in splitted_prediction])\n",
    "    return matched / len(splitted_prediction)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds  = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metric_with_params(tokenizer, metrics_list=['rouge', 'bleu']):\n",
    "    def compute_metrics(eval_preds):\n",
    "\n",
    "        preds, labels = eval_preds\n",
    "\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "        # Replace -100 in the labels as we can't decode them.\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # POST PROCESSING\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        results_dict = {}\n",
    "        for m in metrics_list:\n",
    "            metric = evaluate.load(m)\n",
    "\n",
    "            if m=='bleu':\n",
    "                result = metric.compute(\n",
    "                    predictions=decoded_preds, references=decoded_labels\n",
    "                )\n",
    "            elif m=='rouge':\n",
    "                result = metric.compute(\n",
    "                    predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "                )\n",
    "            result = {key: value for key, value in result.items() if key!='precisions'}\n",
    "\n",
    "            prediction_lens = [\n",
    "                np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "            ]\n",
    "            result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "            result = {k: round(v, 4) for k, v in result.items()}\n",
    "            results_dict.update(result)\n",
    "        return results_dict\n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "###### CV LOOP PREP ########\n",
    "############################\n",
    "\n",
    "DATE_STR = \"20240327\"\n",
    "df = pd.read_csv(f\"./data/processed/conala/{DATE_STR}/all_drifts.csv\")\n",
    "df[\"t_batch\"] = df[\"time_batch\"]\n",
    "df.loc[df.rewritten_intent.isna(), \"rewritten_intent\"] = \"translate an ISO 8601 datetime string into a Python datetime object\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n",
    "\n",
    "full_train_idx = pd.Series(df.loc[df.cluster<=5, \"question_id\"].unique())\n",
    "test_idx = pd.Series(df.loc[df.cluster>5, \"question_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "###### MODEL SETTINGS ######\n",
    "############################\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "compute_metrics = compute_metric_with_params(tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"output_dir\"] = f'reports/upper_bound/results'\n",
    "TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"logging_dir\"] = f'reports/upper_bound/logs'\n",
    "\n",
    "if not os.path.exists('reports/'): \n",
    "    os.mkdir('reports/')\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "        **TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Fold: 0\n",
      "Preparing train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2600' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2600/2600 14:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.908300</td>\n",
       "      <td>3.901278</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>12.465700</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.793800</td>\n",
       "      <td>5210</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.221200</td>\n",
       "      <td>3.808246</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.358400</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>13.263500</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.850400</td>\n",
       "      <td>0.860600</td>\n",
       "      <td>5648</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.666800</td>\n",
       "      <td>3.868564</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>14.113200</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.906400</td>\n",
       "      <td>0.910600</td>\n",
       "      <td>5976</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.261700</td>\n",
       "      <td>3.931495</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>14.929500</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>0.974100</td>\n",
       "      <td>6393</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.991300</td>\n",
       "      <td>4.015207</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>14.493500</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.963100</td>\n",
       "      <td>0.963700</td>\n",
       "      <td>6325</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.789300</td>\n",
       "      <td>4.138397</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>15.755100</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.047200</td>\n",
       "      <td>6873</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.654700</td>\n",
       "      <td>4.107810</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>14.922100</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.980900</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>6439</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>4.160426</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>15.371100</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.027700</td>\n",
       "      <td>6745</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.499400</td>\n",
       "      <td>4.181761</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.350700</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>15.235600</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.018700</td>\n",
       "      <td>6686</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.466900</td>\n",
       "      <td>4.188765</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>15.187400</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.002900</td>\n",
       "      <td>6582</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference\n",
      "Evaluation\n",
      "cuda\n",
      "Fold: 1\n",
      "Preparing train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2650' max='2650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2650/2650 14:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.927300</td>\n",
       "      <td>3.797089</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>12.932700</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.742700</td>\n",
       "      <td>0.770700</td>\n",
       "      <td>5126</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.223100</td>\n",
       "      <td>3.753729</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>15.196200</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.947400</td>\n",
       "      <td>0.948700</td>\n",
       "      <td>6310</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.675800</td>\n",
       "      <td>3.780504</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>14.146200</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>0.868100</td>\n",
       "      <td>5774</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.278700</td>\n",
       "      <td>3.894175</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.896900</td>\n",
       "      <td>5965</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.980700</td>\n",
       "      <td>3.987505</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>16.038500</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.017600</td>\n",
       "      <td>6768</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.788300</td>\n",
       "      <td>4.040753</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>15.430800</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>6630</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.658500</td>\n",
       "      <td>4.033797</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>15.188500</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>0.962300</td>\n",
       "      <td>6400</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.562400</td>\n",
       "      <td>4.072205</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.328600</td>\n",
       "      <td>0.328600</td>\n",
       "      <td>15.548100</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.985900</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>6558</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.499400</td>\n",
       "      <td>4.046926</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>15.467300</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.986500</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>6562</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.469000</td>\n",
       "      <td>4.056290</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>15.582700</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>6590</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference\n",
      "Evaluation\n",
      "cuda\n",
      "Fold: 2\n",
      "Preparing train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2650' max='2650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2650/2650 14:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.940500</td>\n",
       "      <td>3.848444</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.294100</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>15.776100</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.021200</td>\n",
       "      <td>6696</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.214000</td>\n",
       "      <td>3.735567</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>14.467200</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.909600</td>\n",
       "      <td>5964</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>3.840330</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>0.328600</td>\n",
       "      <td>14.411200</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>0.880700</td>\n",
       "      <td>5775</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.284100</td>\n",
       "      <td>3.939187</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>15.413100</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.032800</td>\n",
       "      <td>6772</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.994100</td>\n",
       "      <td>4.012420</td>\n",
       "      <td>0.376300</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>14.625500</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.934500</td>\n",
       "      <td>0.936600</td>\n",
       "      <td>6141</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.803900</td>\n",
       "      <td>4.070661</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>15.698800</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029700</td>\n",
       "      <td>6752</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.662800</td>\n",
       "      <td>4.084267</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>0.328900</td>\n",
       "      <td>15.112000</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.985300</td>\n",
       "      <td>0.985400</td>\n",
       "      <td>6461</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.566900</td>\n",
       "      <td>4.123600</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>15.366800</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.985800</td>\n",
       "      <td>6464</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.504700</td>\n",
       "      <td>4.136731</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>15.635100</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.004900</td>\n",
       "      <td>6589</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>4.152503</td>\n",
       "      <td>0.380200</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>15.196900</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.974400</td>\n",
       "      <td>0.974700</td>\n",
       "      <td>6391</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference\n",
      "Evaluation\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "######### CV TRAINING ######\n",
    "############################\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=RS, shuffle=True)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_train_idx.values)):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Fold: {fold}\")\n",
    "    \n",
    "    fold_results= {}\n",
    "\n",
    "    train_df = df.loc[df.question_id.isin(full_train_idx.iloc[train_idx]),:]\n",
    "    val_df = df.loc[df.question_id.isin(full_train_idx.iloc[val_idx]),:]\n",
    "\n",
    "    train_df, train_dataset = prep_for_hf(train_df)\n",
    "    val_df, val_dataset = prep_for_hf(val_df)\n",
    "\n",
    "    print(\"Preparing train data\")\n",
    "\n",
    "    train_data = train_dataset.map(\n",
    "            lambda batch: batch_tokenize_preprocess(\n",
    "                batch,\n",
    "                tokenizer=tokenizer,\n",
    "                max_input_length=ENCODER_LENGTH,\n",
    "                max_output_length=DECODER_LENGTH,\n",
    "            ),\n",
    "            batch_size=4,\n",
    "            batched=True,\n",
    "            #remove_columns=train_dataset.column_names,\n",
    "        )\n",
    "\n",
    "    print(\"Preparing val data\")\n",
    "\n",
    "    val_data = val_dataset.map(\n",
    "            lambda batch: batch_tokenize_preprocess(\n",
    "                batch,\n",
    "                tokenizer=tokenizer,\n",
    "                max_input_length=ENCODER_LENGTH,\n",
    "                max_output_length=DECODER_LENGTH,\n",
    "            ),\n",
    "            batch_size=4,\n",
    "            batched=True,\n",
    "            #remove_columns=train_dataset.column_names,\n",
    "        )\n",
    "\n",
    "    fold_trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    FOLD_MODEL_PATH = \"./experiments/reports/drift/fold_model\"\n",
    "    if not os.path.exists(FOLD_MODEL_PATH): \n",
    "        os.mkdir(FOLD_MODEL_PATH)\n",
    "\n",
    "    print(\"Training\")\n",
    "    fold_trainer.train()\n",
    "    fold_trainer.save_model(FOLD_MODEL_PATH)\n",
    "\n",
    "    val_ground_truths = val_data[\"output_sequence\"]\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    print(\"Inference\")\n",
    "    # Fine-Tuned\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(FOLD_MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(FOLD_MODEL_PATH, skip_special_tokens=False)\n",
    "    fold_predictions_ft = generate_summary(val_data, model, tokenizer, encoder_max_length=ENCODER_LENGTH, decoder_max_length=DECODER_LENGTH)[1] \n",
    "\n",
    "    # Zero-Shot\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n",
    "    fold_predictions_zs = generate_summary(val_data, model, tokenizer, encoder_max_length=ENCODER_LENGTH, decoder_max_length=DECODER_LENGTH)[1] \n",
    "\n",
    "    # Rouge\n",
    "    print(\"Evaluation\")\n",
    "    fold_predictions_ft_rouge = rouge.compute(references=val_ground_truths, predictions=fold_predictions_ft, use_aggregator=False)[\"rouge1\"]\n",
    "    fold_predictions_zs_rouge = rouge.compute(references=val_ground_truths, predictions=fold_predictions_zs, use_aggregator=False)[\"rouge1\"]\n",
    "    \n",
    "    fold_results[\"input_sequence\"] = val_data[\"input_sequence\"]\n",
    "    fold_results[\"output_sequence\"] = val_ground_truths\n",
    "    fold_results[\"fold_predictions_ft\"] = fold_predictions_ft\n",
    "    fold_results[\"fold_predictions_zs\"] = fold_predictions_zs\n",
    "    fold_results[\"fold_predictions_ft_rouge\"] = fold_predictions_ft_rouge\n",
    "    fold_results[\"fold_predictions_zs_rouge\"] = fold_predictions_zs_rouge\n",
    "\n",
    "    # Combine\n",
    "    fold_results = pd.DataFrame(fold_results)\n",
    "    fold_results[\"fold\"] = fold\n",
    "\n",
    "    if fold==0:\n",
    "        results = fold_results.copy()\n",
    "    else: \n",
    "        results = pd.concat([results, fold_results])\n",
    "\n",
    "results.to_csv(\"./experiments/csv_results/cv_results_drift.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3950' max='3950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3950/3950 27:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.898900</td>\n",
       "      <td>3.667003</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.306100</td>\n",
       "      <td>14.777100</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.017600</td>\n",
       "      <td>17995</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.212900</td>\n",
       "      <td>3.669625</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>12.803400</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.837600</td>\n",
       "      <td>14813</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.726900</td>\n",
       "      <td>3.658848</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>15.481900</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.024900</td>\n",
       "      <td>18125</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.332200</td>\n",
       "      <td>3.750256</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>14.220000</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.886400</td>\n",
       "      <td>0.892400</td>\n",
       "      <td>15781</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.045100</td>\n",
       "      <td>3.814176</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>15.115700</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.979500</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>17325</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.824700</td>\n",
       "      <td>3.893816</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>15.212200</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.008100</td>\n",
       "      <td>17827</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.672700</td>\n",
       "      <td>3.853261</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>15.234200</td>\n",
       "      <td>0.220400</td>\n",
       "      <td>0.990600</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>17519</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.573300</td>\n",
       "      <td>3.909604</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>15.197300</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.001700</td>\n",
       "      <td>17714</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.505800</td>\n",
       "      <td>3.922346</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>15.351300</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>17683</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.469000</td>\n",
       "      <td>3.925814</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>15.230700</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>17656</td>\n",
       "      <td>17684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/dd_spek/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "######## FULL TRAINING #####\n",
    "############################\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "train_df = df.loc[df.question_id.isin(full_train_idx),:]\n",
    "test_df = df.loc[df.question_id.isin(test_idx),:]\n",
    "\n",
    "train_df, train_dataset = prep_for_hf(train_df)\n",
    "test_df, test_dataset = prep_for_hf(test_df)\n",
    "\n",
    "train_data = train_dataset.map(\n",
    "        lambda batch: batch_tokenize_preprocess(\n",
    "            batch,\n",
    "            tokenizer=tokenizer,\n",
    "            max_input_length=ENCODER_LENGTH,\n",
    "            max_output_length=DECODER_LENGTH,\n",
    "        ),\n",
    "        batch_size=4,\n",
    "        batched=True,\n",
    "        #remove_columns=train_dataset.column_names,\n",
    "    )\n",
    "\n",
    "test_data = test_dataset.map(\n",
    "        lambda batch: batch_tokenize_preprocess(\n",
    "            batch,\n",
    "            tokenizer=tokenizer,\n",
    "            max_input_length=ENCODER_LENGTH,\n",
    "            max_output_length=DECODER_LENGTH,\n",
    "        ),\n",
    "        batch_size=4,\n",
    "        batched=True,\n",
    "        #remove_columns=train_dataset.column_names,\n",
    "    )\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "MODEL_PATH = f\"./experiments/reports/drift/saved_model\"\n",
    "if not os.path.exists(MODEL_PATH): \n",
    "    os.mkdir(MODEL_PATH)\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "######### INFERENCE ########\n",
    "############################\n",
    "\n",
    "test_ground_truths = test_data[\"output_sequence\"]\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, skip_special_tokens=False)\n",
    "test_df[\"predictions_ft\"] = generate_summary(test_data, model, tokenizer, encoder_max_length=ENCODER_LENGTH, decoder_max_length=DECODER_LENGTH)[1] \n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n",
    "test_df[\"predictions_zs\"] = generate_summary(test_data, model, tokenizer, encoder_max_length=ENCODER_LENGTH, decoder_max_length=DECODER_LENGTH)[1] \n",
    "\n",
    "############################\n",
    "######## EVALUATION ########\n",
    "############################\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "test_df[\"predictions_ft_rouge\"] = rouge.compute(references=test_ground_truths, predictions=test_df[\"predictions_ft\"].values, use_aggregator=False)[\"rouge1\"]\n",
    "test_df[\"predictions_zs_rouge\"] = rouge.compute(references=test_ground_truths, predictions=test_df[\"predictions_zs\"].values, use_aggregator=False)[\"rouge1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Rouge Zero-Shot 0.2702202093946143\n",
      "Cross Validation Rouge Fine-Tuning 0.3665148879570414\n",
      "Test Rouge Zero-Shot 0.3069821108612329\n",
      "Test Rouge Fine-Tuning 0.4005606151514323\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross Validation Rouge Zero-Shot {results.fold_predictions_zs_rouge.mean()}\")\n",
    "print(f\"Cross Validation Rouge Fine-Tuning {results.fold_predictions_ft_rouge.mean()}\")\n",
    "\n",
    "print(f\"Test Rouge Zero-Shot {test_df.predictions_zs_rouge.mean()}\")\n",
    "print(f\"Test Rouge Fine-Tuning {test_df.predictions_ft_rouge.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"./experiments/csv_results/test_df_drift.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd_spek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
