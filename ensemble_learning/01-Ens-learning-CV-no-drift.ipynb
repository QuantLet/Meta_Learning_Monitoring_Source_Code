{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "##########  DEPENDECIES ############\n",
    "#####################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm # type: ignore\n",
    "import pandas as pd\n",
    "import copy\n",
    "from datetime import datetime, date\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from sklearn.model_selection import KFold, train_test_split # type: ignore\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import utils.prep as pr\n",
    "import utils.eval as ev\n",
    "import utils.inference as infer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "#####################################\n",
    "############  CONSTANTS #############\n",
    "#####################################\n",
    "RS = 42\n",
    "\n",
    "MODEL = \"CodeT5\"\n",
    "BATCH_SIZE = 16\n",
    "DECODER_LENGTH = 20\n",
    "ENCODER_LENGTH = 30\n",
    "ANALYSIS_POSTFIX = f\"mined_no_drift_{str(date.today())}\"\n",
    "DATE_STR = 20240721\n",
    "SEMANTIC_DRIFT = True\n",
    "model_name=\"Salesforce/codet5-base-multi-sum\"\n",
    "\n",
    "FULL_TRAIN_ARGS = {\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DECODER_LENGTH\": DECODER_LENGTH,\n",
    "    \"ENCODER_LENGTH\": ENCODER_LENGTH,\n",
    "    \"MODEL\": MODEL,\n",
    "    \"SEQ_TRAINER_ARGS\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": [0, 1, 5, 8, 10, 16],\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 4,\n",
    "        \"learning_rate\": 6e-6,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"label_smoothing_factor\": 0.1,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"logging_steps\": 100,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"save_strategy\": \"no\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"load_best_model_at_end\": False,\n",
    "        \"output_dir\" : 'reports/results',\n",
    "        \"logging_dir\" : \"reports/logs\",\n",
    "    },\n",
    "}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conala data. Preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  (7941, 11)\n",
      "Test Data:  (2059, 11)\n",
      "Train Data: Cluster cluster\n",
      "3    3498\n",
      "2    3409\n",
      "4     997\n",
      "0      19\n",
      "1      18\n",
      "Name: count, dtype: int64\n",
      "Test Data: Cluster cluster\n",
      "3    1240\n",
      "2     533\n",
      "4     285\n",
      "1       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|████████████████████| 2059/2059 [00:00<00:00, 104699.97 examples/s]\n",
      "Filter: 100%|█████████████████████| 2059/2059 [00:00<00:00, 40289.39 examples/s]\n",
      "Map: 100%|█████████████████████████| 2059/2059 [00:00<00:00, 2128.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(f\"../data/processed/conala/{DATE_STR}/conala_mined_clustered.csv\").head(10000)\n",
    "\n",
    "qids = sorted(dataset.question_id.unique())\n",
    "train_idx, test_idx = qids[:int(len(qids)*0.785)], qids[int(len(qids)*0.785):]\n",
    "test_idx.append(train_idx[0])\n",
    "train_idx.pop(0)\n",
    "train_dataset = dataset[dataset.question_id.isin(train_idx)]\n",
    "test_dataset = dataset[dataset.question_id.isin(test_idx)]\n",
    "\n",
    "\n",
    "print(\"Train Data: \", train_dataset.shape)\n",
    "print(\"Test Data: \", test_dataset.shape)\n",
    "\n",
    "print(\"Train Data: Cluster\", train_dataset.cluster.value_counts())\n",
    "print(\"Test Data: Cluster\", test_dataset.cluster.value_counts())\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset.sample(frac=1, random_state=RS).reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_dataset.sample(frac=1, random_state=RS).reset_index(drop=True))\n",
    "\n",
    "test_data = pr.preprocess_dataset(test_dataset, tokenizer=tokenizer, intent_colum_name=\"intent\")\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df[\"id\"] = test_df.index\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "\n",
    "# Cross Validation\n",
    "folds = KFold(n_splits=3, random_state=RS, shuffle=True)\n",
    "questions_list = np.array(list(set(train_dataset[\"question_id\"])))\n",
    "splits_obj = folds.split(questions_list)\n",
    "splits = []\n",
    "for i, (train_idxs, val_idxs) in enumerate(splits_obj):\n",
    "    print(f\"Fold {i}\")\n",
    "    splits.append([train_idxs, val_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|█████████████████████| 7941/7941 [00:00<00:00, 57650.44 examples/s]\n",
      "Filter: 100%|█████████████████████| 7941/7941 [00:00<00:00, 72436.37 examples/s]\n",
      "Filter: 100%|█████████████████████| 5301/5301 [00:00<00:00, 39013.80 examples/s]\n",
      "Filter: 100%|█████████████████████| 5301/5301 [00:00<00:00, 38065.67 examples/s]\n",
      "Map: 100%|█████████████████████████| 5301/5301 [00:02<00:00, 2283.56 examples/s]\n",
      "Filter: 100%|█████████████████████| 2640/2640 [00:00<00:00, 40756.47 examples/s]\n",
      "Filter: 100%|█████████████████████| 2640/2640 [00:00<00:00, 35303.00 examples/s]\n",
      "Map: 100%|█████████████████████████| 2640/2640 [00:01<00:00, 2165.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 0\n",
      "TRAINING EPOCHS 0\n",
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 1\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1326' max='1326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1326/1326 05:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.538700</td>\n",
       "      <td>4.046259</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.322600</td>\n",
       "      <td>13.605700</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.098000</td>\n",
       "      <td>28110</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 5\n",
      "TRAINING EPOCHS 4\n",
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5304' max='5304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5304/5304 20:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.989200</td>\n",
       "      <td>3.896081</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>13.565900</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.091800</td>\n",
       "      <td>27951</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.869400</td>\n",
       "      <td>3.834083</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>13.675000</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100700</td>\n",
       "      <td>28178</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.751000</td>\n",
       "      <td>3.813528</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>13.501500</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.075900</td>\n",
       "      <td>27543</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.694300</td>\n",
       "      <td>3.808077</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.336600</td>\n",
       "      <td>13.574600</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.083200</td>\n",
       "      <td>27731</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 8\n",
      "TRAINING EPOCHS 3\n",
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3978' max='3978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3978/3978 16:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.516300</td>\n",
       "      <td>3.815096</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>13.472300</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.072200</td>\n",
       "      <td>27449</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.484200</td>\n",
       "      <td>3.807440</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>13.651900</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.088800</td>\n",
       "      <td>27874</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.455200</td>\n",
       "      <td>3.804747</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.333700</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>13.549600</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.076100</td>\n",
       "      <td>27547</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 10\n",
      "TRAINING EPOCHS 2\n",
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2652' max='2652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2652/2652 11:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.909200</td>\n",
       "      <td>3.730794</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>13.562100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.086200</td>\n",
       "      <td>27806</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.777800</td>\n",
       "      <td>3.714485</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>13.679200</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.094500</td>\n",
       "      <td>28020</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 16\n",
      "TRAINING EPOCHS 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7956' max='7956' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7956/7956 29:42, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.610500</td>\n",
       "      <td>3.713634</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>13.448900</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069800</td>\n",
       "      <td>27388</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.578700</td>\n",
       "      <td>3.694589</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>13.743200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.095900</td>\n",
       "      <td>28056</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.535700</td>\n",
       "      <td>3.691576</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>13.648900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.083900</td>\n",
       "      <td>27747</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.470700</td>\n",
       "      <td>3.691134</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.339300</td>\n",
       "      <td>13.654900</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.083500</td>\n",
       "      <td>27737</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.431700</td>\n",
       "      <td>3.692607</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>13.729500</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>27903</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.400400</td>\n",
       "      <td>3.695829</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>13.663600</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.083700</td>\n",
       "      <td>27744</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|█████████████████████| 7941/7941 [00:00<00:00, 66131.57 examples/s]\n",
      "Filter: 100%|█████████████████████| 7941/7941 [00:00<00:00, 78039.37 examples/s]\n",
      "Filter: 100%|█████████████████████| 5290/5290 [00:00<00:00, 39966.11 examples/s]\n",
      "Filter: 100%|█████████████████████| 5290/5290 [00:00<00:00, 40864.87 examples/s]\n",
      "Map: 100%|█████████████████████████| 5290/5290 [00:02<00:00, 2350.42 examples/s]\n",
      "Filter: 100%|█████████████████████| 2651/2651 [00:00<00:00, 39549.91 examples/s]\n",
      "Filter: 100%|█████████████████████| 2651/2651 [00:00<00:00, 43368.93 examples/s]\n",
      "Map: 100%|█████████████████████████| 2651/2651 [00:01<00:00, 2411.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 0\n",
      "TRAINING EPOCHS 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n",
      "TRAINING EPOCH SET 1\n",
      "TRAINING EPOCHS 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1323' max='1323' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1323/1323 04:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.535300</td>\n",
       "      <td>4.048568</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.319200</td>\n",
       "      <td>0.319200</td>\n",
       "      <td>13.494500</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.085900</td>\n",
       "      <td>28024</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 5\n",
      "TRAINING EPOCHS 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5292' max='5292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5292/5292 18:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.986700</td>\n",
       "      <td>3.900426</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>13.237600</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.054000</td>\n",
       "      <td>27202</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.866500</td>\n",
       "      <td>3.837449</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.333900</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>13.404800</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.067700</td>\n",
       "      <td>27555</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.760100</td>\n",
       "      <td>3.811446</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>13.248200</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.051400</td>\n",
       "      <td>27134</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.705000</td>\n",
       "      <td>3.808620</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>13.499400</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.075900</td>\n",
       "      <td>27767</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 8\n",
      "TRAINING EPOCHS 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3969' max='3969' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3969/3969 14:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.520100</td>\n",
       "      <td>3.818031</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>13.163700</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.043100</td>\n",
       "      <td>26921</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.482700</td>\n",
       "      <td>3.807237</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>13.344400</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.058200</td>\n",
       "      <td>27309</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.464500</td>\n",
       "      <td>3.802046</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>13.467000</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.070100</td>\n",
       "      <td>27618</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 10\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2646' max='2646' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2646/2646 09:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.212700</td>\n",
       "      <td>3.863330</td>\n",
       "      <td>0.371900</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.033900</td>\n",
       "      <td>26684</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.219600</td>\n",
       "      <td>3.857049</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>13.293500</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.053200</td>\n",
       "      <td>27180</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 16\n",
      "TRAINING EPOCHS 6\n",
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7938' max='7938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7938/7938 29:59, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.957600</td>\n",
       "      <td>3.952627</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>12.904200</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.015100</td>\n",
       "      <td>26197</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.060700</td>\n",
       "      <td>3.878911</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>13.149400</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.041800</td>\n",
       "      <td>26887</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.207100</td>\n",
       "      <td>3.838570</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>13.197300</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.047500</td>\n",
       "      <td>27033</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.247200</td>\n",
       "      <td>3.827990</td>\n",
       "      <td>0.367500</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>13.384000</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.065300</td>\n",
       "      <td>27492</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.224500</td>\n",
       "      <td>3.835048</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>13.361000</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.063900</td>\n",
       "      <td>27456</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.203400</td>\n",
       "      <td>3.839550</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.323100</td>\n",
       "      <td>13.367400</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.062800</td>\n",
       "      <td>27429</td>\n",
       "      <td>25808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|█████████████████████| 7941/7941 [00:00<00:00, 57455.33 examples/s]\n",
      "Filter: 100%|█████████████████████| 7941/7941 [00:00<00:00, 69940.59 examples/s]\n",
      "Filter: 100%|█████████████████████| 5291/5291 [00:00<00:00, 31006.63 examples/s]\n",
      "Filter: 100%|█████████████████████| 5291/5291 [00:00<00:00, 31246.74 examples/s]\n",
      "Map: 100%|█████████████████████████| 5291/5291 [00:02<00:00, 1894.59 examples/s]\n",
      "Filter: 100%|█████████████████████| 2650/2650 [00:00<00:00, 31129.48 examples/s]\n",
      "Filter: 100%|█████████████████████| 2650/2650 [00:00<00:00, 34234.89 examples/s]\n",
      "Map: 100%|█████████████████████████| 2650/2650 [00:01<00:00, 1957.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 0\n",
      "TRAINING EPOCHS 0\n",
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 1\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1323' max='1323' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1323/1323 04:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.526800</td>\n",
       "      <td>4.070565</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>13.511700</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.074700</td>\n",
       "      <td>27998</td>\n",
       "      <td>26052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 5\n",
      "TRAINING EPOCHS 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL ./tmp/\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3970' max='5292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3970/5292 12:24 < 04:08, 5.33 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.972400</td>\n",
       "      <td>3.923131</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>13.525700</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.073100</td>\n",
       "      <td>27957</td>\n",
       "      <td>26052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.849700</td>\n",
       "      <td>3.871617</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>13.601100</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.072700</td>\n",
       "      <td>27946</td>\n",
       "      <td>26052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='426' max='663' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [426/663 01:19 < 00:44, 5.33 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_results = {}\n",
    "for epoch_i, epoch_set in enumerate(sorted(FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"])):\n",
    "    fold_results[epoch_set] = {}\n",
    "\n",
    "for i, (train_idxs, val_idxs) in enumerate(splits):\n",
    "\n",
    "    print(f\"Fold {i}\")\n",
    "    fold_dataset = DatasetDict({\n",
    "        \"train\": train_dataset.filter(lambda q_id: q_id[\"question_id\"] in questions_list[train_idxs]),\n",
    "        \"validation\": train_dataset.filter(lambda q_id: q_id[\"question_id\"] in questions_list[val_idxs]),\n",
    "    })\n",
    "    fold_train = pr.preprocess_dataset(fold_dataset[\"train\"], tokenizer=tokenizer, intent_colum_name=\"intent\")\n",
    "    fold_val = pr.preprocess_dataset(fold_dataset[\"validation\"], tokenizer=tokenizer, intent_colum_name=\"intent\")\n",
    "    \n",
    "\n",
    "    for epoch_i, epoch_set in enumerate(sorted(FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"])):\n",
    "\n",
    "        fold_df = pd.DataFrame(fold_val)\n",
    "        print(f\"TRAINING EPOCH SET {epoch_set}\")\n",
    "\n",
    "        TRAIN_ARGS = copy.deepcopy(FULL_TRAIN_ARGS)\n",
    "        FOLD_MODEL_PATH = \"./tmp/\"\n",
    "\n",
    "        if epoch_set > 1: \n",
    "            TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = epoch_set - latest_run_epoch\n",
    "        else:\n",
    "            TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = epoch_set\n",
    "        \n",
    "        print(f'TRAINING EPOCHS {TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"]}')\n",
    "\n",
    "        if epoch_set > 1: \n",
    "            model = AutoModelForSeq2SeqLM.from_pretrained(FOLD_MODEL_PATH)\n",
    "            print(f\"LOADING MODEL {FOLD_MODEL_PATH}\")\n",
    "        else: \n",
    "            model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "            print(f\"LOADING MODEL {model_name}\")\n",
    "\n",
    "        print(device)\n",
    "        model.to(device)\n",
    "\n",
    "        data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "        compute_metrics = ev.compute_metric_with_params(tokenizer) \n",
    "\n",
    "        if not os.path.exists(f'reports/'): \n",
    "            os.mkdir(f'reports/')\n",
    "\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "                **TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"],\n",
    "            )\n",
    "        \n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=fold_train,\n",
    "            eval_dataset=fold_val,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        if epoch_set!=0:\n",
    "            trainer.train()\n",
    "\n",
    "        text = fold_val[\"input_sequence\"]\n",
    "        summaries = []\n",
    "        \n",
    "        if len(text)>1000:\n",
    "            \n",
    "            batch_size = 1000\n",
    "            n_batches = math.ceil(len(text)/batch_size)\n",
    "\n",
    "            for batch in range(n_batches):\n",
    "\n",
    "                batch_start_idx = batch*batch_size\n",
    "                batch_end_idx = batch*batch_size + batch_size\n",
    "\n",
    "                if batch==(n_batches-1):\n",
    "                    batch_end_idx = len(text)\n",
    "                summary = infer.generate_summary(text[batch_start_idx:batch_end_idx],\n",
    "                                                model,\n",
    "                                                tokenizer,\n",
    "                                                TRAIN_ARGS[\"ENCODER_LENGTH\"],\n",
    "                                                TRAIN_ARGS[\"DECODER_LENGTH\"])[1]\n",
    "                summaries.append(summary)\n",
    "\n",
    "            summaries = [sentence for summary_list in summaries for sentence in summary_list]\n",
    "            \n",
    "            fold_df[\"prediction\"] = summaries\n",
    "        else: \n",
    "            summaries = infer.generate_summary(text, \n",
    "                                               model,\n",
    "                                               tokenizer,\n",
    "                                               TRAIN_ARGS[\"ENCODER_LENGTH\"],\n",
    "                                               TRAIN_ARGS[\"DECODER_LENGTH\"])\n",
    "            fold_df[\"prediction\"] = summaries[1]\n",
    "\n",
    "\n",
    "        fold_df[\"rouge\"] = rouge.compute(predictions=fold_df[\"prediction\"], \n",
    "                    references=fold_df[\"output_sequence\"],\n",
    "                    use_stemmer=True, \n",
    "                    use_aggregator=False,\n",
    "                    rouge_types=[\"rouge1\"])[\"rouge1\"]\n",
    "        \n",
    "        fold_results[epoch_set][i] = fold_df\n",
    "        \n",
    "        ########## SAVE FOLD MODEL\n",
    "        if not os.path.exists(FOLD_MODEL_PATH): \n",
    "            os.mkdir(FOLD_MODEL_PATH)\n",
    "\n",
    "        trainer.save_model(FOLD_MODEL_PATH)\n",
    "\n",
    "        latest_run_epoch = epoch_set\n",
    "\n",
    "########## CONVERT TO DATAFRAME\n",
    "\n",
    "for epoch_i, (epoch_set) in enumerate(fold_results.keys()): \n",
    "    \n",
    "    for i, (k, f_df) in enumerate(fold_results[epoch_set].items()): \n",
    "        \n",
    "        f_df['fold'] = k\n",
    "        f_df['epoch_set'] = epoch_set\n",
    "\n",
    "        if (epoch_i==0 and i==0): \n",
    "            cv_df = f_df.copy()\n",
    "        else: \n",
    "            cv_df = pd.concat([cv_df, f_df])\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open(f'reports/results/cv_result_{ANALYSIS_POSTFIX}.pickle', 'wb') as handle:\n",
    "    pickle.dump(cv_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOAD CV RESULTS\n",
    "\n",
    "import pickle\n",
    "with open(f'reports/results/cv_result_{ANALYSIS_POSTFIX}.pickle', 'rb') as handle:\n",
    "    cv_df = pickle.load(handle)\n",
    "\n",
    "########## ROUGE PER SETTING\n",
    "\n",
    "print(\"Mean\")\n",
    "print(cv_df.groupby([\"epoch_set\"])[\"rouge\"].mean())\n",
    "\n",
    "print(\"STD\")\n",
    "print(cv_df.groupby(\"epoch_set\")[\"rouge\"].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Learn performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_two(X_train, y_train, model, X_val=None, y_val=None,  save=False): \n",
    "    global ANALYSIS_POSTFIX\n",
    "    \n",
    "    if model==\"lr\":\n",
    "        reg = LinearRegression().fit(X_train, y_train)\n",
    "    elif model ==\"svm\": \n",
    "        reg = SVR().fit(X_train, y_train)\n",
    "    elif model==\"rf\":\n",
    "        reg = RandomForestRegressor.fit(X_train, y_train)\n",
    "    elif model==\"lgbm\":\n",
    "        reg = LGBMRegressor()\n",
    "        reg.fit(X=X_train, y=y_train)\n",
    "    elif model==\"catboost\":\n",
    "        reg = CatBoostRegressor()\n",
    "        reg.fit(X=X_train, y=y_train)\n",
    "\n",
    "    if save:\n",
    "        with open(f'./models/reg_{model}_{ANALYSIS_POSTFIX}.pkl','wb') as f:\n",
    "            pickle.dump(reg, f)\n",
    "        return f'./models/reg_{model}_{ANALYSIS_POSTFIX}.pkl'\n",
    "    \n",
    "    else:\n",
    "        y_pred = reg.predict(X_val)\n",
    "        y_pred[y_pred<0] = 0\n",
    "        mae = mean_absolute_error(y_true=y_val, y_pred=y_pred)\n",
    "        rmse = math.sqrt(mean_squared_error(y_true=y_val, y_pred=y_pred))\n",
    "        return {\"pred\": y_pred, \"mae\": mae, \"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_models = [\"lr\", \"svm\", \"lgbm\", \"catboost\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "for test_fold in range(cv_df.fold.max()+1):\n",
    "    print(test_fold)\n",
    "\n",
    "    # Prepare the input data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer.fit_transform(cv_df.loc[cv_df.fold!=test_fold, \"input_sequence\"])\n",
    "    X_train_column_sparse = pd.get_dummies(cv_df.loc[cv_df.fold!=test_fold, \"epoch_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "    X_train = hstack([X_train_column_sparse, X_train_tfidf])\n",
    "    y_train = cv_df.loc[cv_df.fold!=test_fold, \"rouge\"]\n",
    "    \n",
    "    X_val_tfidf = vectorizer.transform(cv_df.loc[cv_df.fold==test_fold, \"input_sequence\"])\n",
    "    X_val_column_sparse = pd.get_dummies(cv_df.loc[cv_df.fold==test_fold, \"epoch_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "    X_val = hstack([X_val_column_sparse, X_val_tfidf])\n",
    "    y_val = cv_df.loc[cv_df.fold==test_fold, \"rouge\"]\n",
    "\n",
    "    results[test_fold] = {}\n",
    "    for model in t_models:\n",
    "        print(model)\n",
    "        preds_df = step_two(X_train=X_train,\n",
    "                            y_train=y_train,\n",
    "                            X_val=X_val,\n",
    "                            y_val=y_val,\n",
    "                            model=model)\n",
    "        cv_df.loc[cv_df.fold==test_fold, f\"{model}_perf_hat\"] = preds_df[\"pred\"]\n",
    "        results[test_fold][model] = preds_df\n",
    "\n",
    "cv_df = cv_df.reset_index(drop=True)\n",
    "\n",
    "# ENSEMBLE ESTIMATE (JUST HIGHEST PREDICTIONS)\n",
    "models_index = cv_df.groupby(\"id\")[\"catboost_perf_hat\"].idxmax()\n",
    "optimal_ensemble = cv_df.iloc[models_index][[\"id\", \"epoch_set\"]]\n",
    "optimal_ensemble_map = dict(zip(optimal_ensemble.id, optimal_ensemble.epoch_set))\n",
    "cv_df[\"opt_es_id\"] = cv_df.id.map(optimal_ensemble_map)\n",
    "ensemble_preds = cv_df.loc[cv_df[\"epoch_set\"]==cv_df[\"opt_es_id\"], :]\n",
    "ensemble_preds[\"rouge\"].mean()\n",
    "ensemble_preds[\"epoch_set\"] = \"ensemble\"\n",
    "cv_df = pd.concat([cv_df, ensemble_preds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby(\"epoch_set\").catboost_perf_hat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby(\"epoch_set\").catboost_perf_hat.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the file\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model in t_models:\n",
    "    model_results[model]= {}\n",
    "    model_results[model][\"rmse\"] = []\n",
    "    model_results[model][\"mae\"] = [] \n",
    "\n",
    "    for fold in range(3):\n",
    "    \n",
    "        model_results[model][\"mae\"].append(results[fold][model][\"mae\"])\n",
    "        model_results[model][\"rmse\"].append(results[fold][model][\"rmse\"])\n",
    "    \n",
    "    model_results[model][\"rmse_avg\"] = np.array(model_results[model][\"rmse\"]).mean()\n",
    "    model_results[model][\"mae_avg\"] = np.array(model_results[model][\"mae\"]).mean()\n",
    "\n",
    "    model_results[model][\"rmse_std\"] = np.array(model_results[model][\"rmse\"]).std()\n",
    "    model_results[model][\"mae_std\"] = np.array(model_results[model][\"mae\"]).std()\n",
    "\n",
    "for model in t_models:\n",
    "    print(model)\n",
    "    print(\"RMSE \", model_results[model][\"rmse_avg\"])\n",
    "    print(\"MAE \",model_results[model][\"mae_avg\"])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"RMSE STD \", model_results[model][\"rmse_std\"])\n",
    "    print(\"MAE STD\",model_results[model][\"mae_std\"])\n",
    "    print(\"\\n\")\n",
    "\n",
    "with open(f'reports/results/s2_model_results_{ANALYSIS_POSTFIX}.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f'reports/results/cd_df_with_s2_{ANALYSIS_POSTFIX}.pickle', 'wb') as handle:\n",
    "    pickle.dump(cv_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO SAVE THE VECTORIZER AND STEP 2 MODELS\n",
    "\n",
    "with open(f'reports/results/cd_df_with_s2_{ANALYSIS_POSTFIX}.pickle', 'rb') as handle:\n",
    "    cv_df = pickle.load(handle)\n",
    "\n",
    "# TRAIN ON ALL PREDICTIONS AT ONCE\n",
    "\n",
    "t_models = [\"lr\", \"svm\", \"lgbm\", \"catboost\"]\n",
    "\n",
    "# Prepare the input data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(cv_df.loc[cv_df.epoch_set!=\"ensemble\", \"input_sequence\"])\n",
    "X_train_column_sparse = pd.get_dummies(cv_df.loc[cv_df.epoch_set!=\"ensemble\", \"epoch_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "X_train = hstack([X_train_column_sparse, X_train_tfidf])\n",
    "y_train = cv_df.loc[cv_df.epoch_set!=\"ensemble\", \"rouge\"]\n",
    "    \n",
    "with open(f\"./models/vectorizer_{ANALYSIS_POSTFIX}.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "      \n",
    "for model in t_models:\n",
    "    print(model)\n",
    "    preds_df = step_two(X_train=X_train,\n",
    "                        y_train=y_train,\n",
    "                        model=model,\n",
    "                        save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "ensemble"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
