{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "##########  DEPENDECIES ############\n",
    "#####################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm # type: ignore\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from sklearn.model_selection import KFold # type: ignore\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import utils.prep as pr\n",
    "import utils.eval as ev\n",
    "import utils.inference as infer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "#####################################\n",
    "############  CONSTANTS #############\n",
    "#####################################\n",
    "RS = 42\n",
    "\n",
    "MODEL = \"CodeT5\"\n",
    "TRAIN_N = 330\n",
    "BATCH_SIZE = 15\n",
    "DECODER_LENGTH = 20\n",
    "ENCODER_LENGTH = 15\n",
    "\n",
    "FULL_TRAIN_ARGS = {\n",
    "    \"TRAIN_N\": TRAIN_N,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DECODER_LENGTH\": DECODER_LENGTH,\n",
    "    \"ENCODER_LENGTH\": ENCODER_LENGTH,\n",
    "    \"MODEL\": MODEL,\n",
    "    \"SEQ_TRAINER_ARGS\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": [0, 1, 2, 3, 4, 7, 9],\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 4,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"label_smoothing_factor\": 0.1,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"logging_steps\": 100,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"save_strategy\": \"no\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"load_best_model_at_end\": False,\n",
    "    },\n",
    "}\n",
    "FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"output_dir\"] = f'reports/results'\n",
    "FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"logging_dir\"] = f'reports/logs'\n",
    "\n",
    "model_name=\"Salesforce/codet5-base-multi-sum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conala data. Preprocessing. Sampling as in the paper (further, random sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4 obsevations:  (344, 6)\n",
      "Cluster not 4 obsevations:  (156, 6)\n",
      "Train Data:  (2379, 6)\n",
      "Test Data:  (500, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 140631.82 examples/s]\n",
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 61298.99 examples/s]\n",
      "Map: 100%|██████████| 2379/2379 [00:01<00:00, 2120.28 examples/s]\n",
      "Filter: 100%|██████████| 500/500 [00:00<00:00, 84294.06 examples/s]\n",
      "Filter: 100%|██████████| 500/500 [00:00<00:00, 46328.50 examples/s]\n",
      "Map: 100%|██████████| 499/499 [00:00<00:00, 2546.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(f\"../data/processed/conala/20240327/conala_clustered.csv\")\n",
    "dataset = dataset.drop(\"time_batch\", axis=1)\n",
    "\n",
    "test_4_examples = dataset[dataset[\"cluster\"]==4].sample(frac=0.85, random_state=RS)\n",
    "print(\"Cluster 4 obsevations: \", test_4_examples.shape)\n",
    "test_non4_examples = dataset[dataset[\"cluster\"]!=4].sample(n=156, random_state=RS)\n",
    "print(\"Cluster not 4 obsevations: \", test_non4_examples.shape)\n",
    "\n",
    "test_dataset = pd.concat([test_4_examples, test_non4_examples])\n",
    "train_dataset = dataset[~dataset.index.isin(test_dataset.index)]\n",
    "print(\"Train Data: \", train_dataset.shape)\n",
    "print(\"Test Data: \", test_dataset.shape)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset.sample(frac=1, random_state=RS).reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_dataset.sample(frac=1, random_state=RS).reset_index(drop=True))\n",
    "\n",
    "train_data = pr.preprocess_dataset(train_dataset, tokenizer=tokenizer)\n",
    "test_data = pr.preprocess_dataset(test_dataset, tokenizer=tokenizer)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df[\"id\"] = test_df.index\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_perf(X, model): \n",
    "\n",
    "    with open(f'./models/reg_{model}_drift.pkl','rb') as f:\n",
    "                        reg = pickle.load(f)\n",
    "    y_pred = reg.predict(X)\n",
    "    y_pred[y_pred<0] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "catboost\n"
     ]
    }
   ],
   "source": [
    "### Step 1. PREDICT PERFORMANCE\n",
    "\n",
    "# TRAIN ON ALL PREDICTIONS AT ONCE\n",
    "\n",
    "t_models = [\"svm\", \"catboost\"]\n",
    "\n",
    "for i, model_id in enumerate(['epoch_set_0', 'epoch_set_1', 'epoch_set_2', 'epoch_set_3',\n",
    "       'epoch_set_4', 'epoch_set_7', 'epoch_set_9', 'cluster_set_0',\n",
    "       'cluster_set_1', 'cluster_set_2', 'cluster_set_3', 'cluster_set_4',\n",
    "       'cluster_set_5', 'cluster_set_6']):\n",
    "\n",
    "    set_df = test_df.copy()\n",
    "    set_df[\"model_id\"] = model_id\n",
    "    # Prepare the input data\n",
    "    with open(\"./models/vectorizer_drift.pkl\", \"rb\") as file:\n",
    "        vectorizer = pickle.load(file)\n",
    "\n",
    "    if i==0:\n",
    "        meta_preds_df = set_df.copy()\n",
    "    else: \n",
    "        meta_preds_df = pd.concat([meta_preds_df, set_df])\n",
    "         \n",
    "X_test_tfidf = vectorizer.transform(meta_preds_df.loc[:, \"input_sequence\"])\n",
    "X_test_column_sparse = pd.get_dummies(meta_preds_df.loc[:, \"model_id\"], sparse=True).sparse.to_coo().tocsr()\n",
    "X_test = hstack([X_test_column_sparse, X_test_tfidf])\n",
    "#y_test = test_df.loc[:, \"rouge\"]\n",
    "\n",
    "models_preds = []\n",
    "for model in t_models:\n",
    "    print(model)\n",
    "    meta_preds_df[f\"{model}_preds\"] = pred_perf(X_test, model)\n",
    "\n",
    "meta_preds_df = meta_preds_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id\n",
       "cluster_set_0    0.425801\n",
       "cluster_set_1    0.404294\n",
       "cluster_set_2    0.407196\n",
       "cluster_set_3    0.433571\n",
       "cluster_set_4    0.316861\n",
       "cluster_set_5    0.352937\n",
       "cluster_set_6    0.405486\n",
       "epoch_set_0      0.317432\n",
       "epoch_set_1      0.467290\n",
       "epoch_set_2      0.469011\n",
       "epoch_set_3      0.467313\n",
       "epoch_set_4      0.461308\n",
       "epoch_set_7      0.467185\n",
       "epoch_set_9      0.462042\n",
       "Name: catboost_preds, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_preds_df.groupby(\"model_id\").catboost_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_index = meta_preds_df.groupby(\"id\")[\"catboost_preds\"].idxmax()\n",
    "optimal_ensemble = meta_preds_df.iloc[models_index][[\"id\", \"model_id\"]]\n",
    "optimal_ensemble_map = dict(zip(optimal_ensemble.id, optimal_ensemble.model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 0\n",
      "TRAINING EPOCHS 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 1\n",
      "TRAINING EPOCHS 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [595/595 01:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>3.491663</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>13.607200</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>5410</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 2\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL ./models/1_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [595/595 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.781000</td>\n",
       "      <td>3.457503</td>\n",
       "      <td>0.441800</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>14.012000</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.962300</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>5602</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 3\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL ./models/2_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [595/595 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.295800</td>\n",
       "      <td>3.527485</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>14.046100</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>5609</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 4\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL ./models/3_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [595/595 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.013600</td>\n",
       "      <td>3.640005</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>14.338700</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>5775</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 7\n",
      "TRAINING EPOCHS 3\n",
      "LOADING MODEL ./models/4_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1785' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1785/1785 04:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.876500</td>\n",
       "      <td>3.496290</td>\n",
       "      <td>0.436100</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>13.563100</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.907200</td>\n",
       "      <td>0.911300</td>\n",
       "      <td>5301</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.598900</td>\n",
       "      <td>3.477729</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.405300</td>\n",
       "      <td>0.405300</td>\n",
       "      <td>14.130300</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.971100</td>\n",
       "      <td>0.971500</td>\n",
       "      <td>5651</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.352700</td>\n",
       "      <td>3.551478</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>14.338700</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.989600</td>\n",
       "      <td>0.989700</td>\n",
       "      <td>5757</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 9\n",
      "TRAINING EPOCHS 2\n",
      "LOADING MODEL ./models/7_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 03:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.676400</td>\n",
       "      <td>3.678091</td>\n",
       "      <td>0.434500</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.396200</td>\n",
       "      <td>14.797600</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.019800</td>\n",
       "      <td>5932</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.882600</td>\n",
       "      <td>3.716435</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>14.328700</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0.976200</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>5680</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "latest_run_epoch = 0\n",
    "\n",
    "for epoch_i, epoch_set in enumerate(sorted(FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"])):\n",
    "\n",
    "    set_df = test_df.copy()\n",
    "    print(f\"TRAINING EPOCH SET {epoch_set}\")\n",
    "\n",
    "    TRAIN_ARGS = copy.deepcopy(FULL_TRAIN_ARGS)\n",
    "    MODEL_PATH = f\"./models/{epoch_set}_epoch_set\"\n",
    "    PREV_MODEL_PATH = f\"./models/{latest_run_epoch}_epoch_set\"\n",
    "    \n",
    "\n",
    "    results[epoch_set] = {}\n",
    "\n",
    "    if epoch_set > 1: \n",
    "        TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = epoch_set - latest_run_epoch\n",
    "    else:\n",
    "        TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = epoch_set\n",
    "    \n",
    "    print(f'TRAINING EPOCHS {TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"]}')\n",
    "\n",
    "    if epoch_set > 1: \n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(PREV_MODEL_PATH)\n",
    "        print(f\"LOADING MODEL {PREV_MODEL_PATH}\")\n",
    "    else: \n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        print(f\"LOADING MODEL {model_name}\")\n",
    "\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    compute_metrics = ev.compute_metric_with_params(tokenizer) \n",
    "\n",
    "    if not os.path.exists(f'reports/'): \n",
    "        os.mkdir(f'reports/')\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "            **TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"],\n",
    "        )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    if epoch_set!=0:\n",
    "        trainer.train()\n",
    "\n",
    "    text = list(test_df[\"input_sequence\"].values)\n",
    "    summaries = infer.generate_summary(text, model, tokenizer, TRAIN_ARGS[\"ENCODER_LENGTH\"], TRAIN_ARGS[\"DECODER_LENGTH\"])\n",
    "    \n",
    "    \n",
    "    set_df[\"model_id\"] = \"epoch_set_\" + str(epoch_set)\n",
    "    set_df[\"prediction\"] = summaries[1]\n",
    "    set_df[\"rouge\"] = rouge.compute(predictions=set_df[\"prediction\"], \n",
    "                references=set_df[\"output_sequence\"],\n",
    "                use_stemmer=True, \n",
    "                use_aggregator=False,\n",
    "                rouge_types=[\"rouge1\"])[\"rouge1\"]\n",
    "\n",
    "    if epoch_set==0:\n",
    "        test_result_df = set_df.copy()\n",
    "    else: \n",
    "        test_result_df = pd.concat([test_result_df, set_df])\n",
    "\n",
    "\n",
    "    \n",
    "    ########## SAVE EPOCH SET MODEL\n",
    "    if not os.path.exists(MODEL_PATH): \n",
    "        os.mkdir(MODEL_PATH)\n",
    "\n",
    "    trainer.save_model(MODEL_PATH)\n",
    "\n",
    "    latest_run_epoch = epoch_set\n",
    "\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open('test_results_df_drift.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_result_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_results_df_drift.pickle', 'rb') as handle:\n",
    "    test_result_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [1, 2]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 33241.99 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='198' max='198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [198/198 01:14, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.287700</td>\n",
       "      <td>3.907113</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.325100</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>11.398800</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.751600</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>4525</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.171300</td>\n",
       "      <td>3.793663</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>12.386800</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.848200</td>\n",
       "      <td>4934</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [3, 4]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 33007.55 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.535000</td>\n",
       "      <td>3.948033</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>9.883800</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>3747</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.456900</td>\n",
       "      <td>3.746688</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>11.322600</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>4367</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [5, 6]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 33208.69 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.325600</td>\n",
       "      <td>4.064366</td>\n",
       "      <td>0.342900</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>9.853700</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>0.650700</td>\n",
       "      <td>3785</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.240900</td>\n",
       "      <td>3.877703</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>10.843700</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>4218</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [7, 8]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 33469.46 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='442' max='442' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [442/442 01:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.773700</td>\n",
       "      <td>3.763443</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>12.072100</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.816600</td>\n",
       "      <td>0.831500</td>\n",
       "      <td>4837</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.971500</td>\n",
       "      <td>3.701935</td>\n",
       "      <td>0.384400</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>12.246500</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.822700</td>\n",
       "      <td>0.836700</td>\n",
       "      <td>4867</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [4]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 32637.24 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.282100</td>\n",
       "      <td>5.074299</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>0.277100</td>\n",
       "      <td>9.573100</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>3632</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.844900</td>\n",
       "      <td>4.773075</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>9.406800</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.516600</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>3503</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [5]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 32828.05 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.737400</td>\n",
       "      <td>4.645225</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.289800</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>8.396800</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.404200</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>3052</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.688300</td>\n",
       "      <td>4.156934</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>9.793600</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>3728</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET [1]\n",
      "TRAINING EPOCHS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2379/2379 [00:00<00:00, 31185.05 examples/s]\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.429400</td>\n",
       "      <td>4.075424</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>11.152300</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.763800</td>\n",
       "      <td>4443</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.235700</td>\n",
       "      <td>3.867348</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>11.711400</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.777600</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>4648</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "latest_run_epoch = 0\n",
    "cluster_models = [[1,2], [3,4], [5,6], [7,8], [4], [5], [1]]\n",
    "\n",
    "for cluster_i, cluster_set in enumerate(cluster_models):\n",
    "\n",
    "    set_df = test_df.copy()\n",
    "    print(f\"TRAINING EPOCH SET {cluster_set}\")\n",
    "\n",
    "    TRAIN_ARGS = copy.deepcopy(FULL_TRAIN_ARGS)\n",
    "    MODEL_PATH = f\"./models/{cluster_set}_cluster_set\"\n",
    "\n",
    "    results[cluster_i] = {}\n",
    "\n",
    "    TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = 2\n",
    "    \n",
    "    print(f'TRAINING EPOCHS {TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"]}')\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    print(f\"LOADING MODEL {model_name}\")\n",
    "\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    compute_metrics = ev.compute_metric_with_params(tokenizer) \n",
    "\n",
    "    if not os.path.exists(f'reports/'): \n",
    "        os.mkdir(f'reports/')\n",
    "\n",
    "    train_data_cl = train_data.filter(lambda q_id: q_id[\"cluster\"] in cluster_set)\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "            **TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"],\n",
    "        )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_data_cl,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    text = list(test_df[\"input_sequence\"].values)\n",
    "    summaries = infer.generate_summary(text, model, tokenizer, TRAIN_ARGS[\"ENCODER_LENGTH\"], TRAIN_ARGS[\"DECODER_LENGTH\"])\n",
    "    \n",
    "    \n",
    "    set_df[\"model_id\"] = \"cluster_set_\" + str(cluster_i)\n",
    "    set_df[\"prediction\"] = summaries[1]\n",
    "    set_df[\"rouge\"] = rouge.compute(predictions=set_df[\"prediction\"], \n",
    "                references=set_df[\"output_sequence\"],\n",
    "                use_stemmer=True, \n",
    "                use_aggregator=False,\n",
    "                rouge_types=[\"rouge1\"])[\"rouge1\"]\n",
    "\n",
    "    if cluster_i==0:\n",
    "        test_result_df_cluster = set_df.copy()\n",
    "    else: \n",
    "        test_result_df_cluster = pd.concat([test_result_df_cluster, set_df])\n",
    "\n",
    "    ########## SAVE EPOCH SET MODEL\n",
    "    if not os.path.exists(MODEL_PATH): \n",
    "        os.mkdir(MODEL_PATH)\n",
    "\n",
    "    trainer.save_model(MODEL_PATH)\n",
    "\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open('test_results_df_drift_cluster.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_result_df_cluster, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_df = pd.concat([test_result_df, test_result_df_cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "model_id\n",
      "cluster_set_0    0.376832\n",
      "cluster_set_1    0.385097\n",
      "cluster_set_2    0.363805\n",
      "cluster_set_3    0.385271\n",
      "cluster_set_4    0.310305\n",
      "cluster_set_5    0.334277\n",
      "cluster_set_6    0.352585\n",
      "epoch_set_0      0.298044\n",
      "epoch_set_1      0.430842\n",
      "epoch_set_2      0.442460\n",
      "epoch_set_3      0.442200\n",
      "epoch_set_4      0.446764\n",
      "epoch_set_7      0.446796\n",
      "epoch_set_9      0.438847\n",
      "Name: rouge, dtype: float64\n",
      "STD\n",
      "model_id\n",
      "cluster_set_0    0.198200\n",
      "cluster_set_1    0.193605\n",
      "cluster_set_2    0.189683\n",
      "cluster_set_3    0.195546\n",
      "cluster_set_4    0.185538\n",
      "cluster_set_5    0.187413\n",
      "cluster_set_6    0.197707\n",
      "epoch_set_0      0.181991\n",
      "epoch_set_1      0.210997\n",
      "epoch_set_2      0.214399\n",
      "epoch_set_3      0.216437\n",
      "epoch_set_4      0.217598\n",
      "epoch_set_7      0.225082\n",
      "epoch_set_9      0.224611\n",
      "Name: rouge, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "########## ROUGE PER SETTING\n",
    "\n",
    "print(\"Mean\")\n",
    "print(test_result_df.groupby(\"model_id\")[\"rouge\"].mean())\n",
    "\n",
    "print(\"STD\")\n",
    "print(test_result_df.groupby(\"model_id\")[\"rouge\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44504511636607547"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ENSEMBLE COMPUTE\n",
    "test_result_df[\"opt_es_id\"] = test_result_df.id.map(optimal_ensemble_map)\n",
    "ensemble_preds = test_result_df.loc[test_result_df[\"model_id\"]==test_result_df[\"opt_es_id\"], :]\n",
    "ensemble_preds[\"rouge\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'epoch_set_3',\n",
       " 1: 'epoch_set_2',\n",
       " 2: 'epoch_set_2',\n",
       " 3: 'epoch_set_2',\n",
       " 4: 'epoch_set_2',\n",
       " 5: 'epoch_set_7',\n",
       " 6: 'epoch_set_2',\n",
       " 7: 'epoch_set_2',\n",
       " 8: 'epoch_set_2',\n",
       " 9: 'epoch_set_2',\n",
       " 10: 'epoch_set_2',\n",
       " 11: 'epoch_set_1',\n",
       " 12: 'epoch_set_2',\n",
       " 13: 'epoch_set_2',\n",
       " 14: 'epoch_set_2',\n",
       " 15: 'epoch_set_2',\n",
       " 16: 'epoch_set_2',\n",
       " 17: 'epoch_set_2',\n",
       " 18: 'epoch_set_2',\n",
       " 19: 'epoch_set_2',\n",
       " 20: 'epoch_set_2',\n",
       " 21: 'epoch_set_2',\n",
       " 22: 'epoch_set_2',\n",
       " 23: 'epoch_set_2',\n",
       " 24: 'epoch_set_2',\n",
       " 25: 'epoch_set_2',\n",
       " 26: 'epoch_set_2',\n",
       " 27: 'epoch_set_2',\n",
       " 28: 'epoch_set_1',\n",
       " 29: 'epoch_set_2',\n",
       " 30: 'epoch_set_2',\n",
       " 31: 'epoch_set_2',\n",
       " 32: 'epoch_set_2',\n",
       " 33: 'epoch_set_7',\n",
       " 34: 'epoch_set_2',\n",
       " 35: 'epoch_set_2',\n",
       " 36: 'epoch_set_7',\n",
       " 37: 'epoch_set_2',\n",
       " 38: 'epoch_set_2',\n",
       " 39: 'epoch_set_2',\n",
       " 40: 'epoch_set_2',\n",
       " 41: 'epoch_set_2',\n",
       " 42: 'epoch_set_1',\n",
       " 43: 'epoch_set_2',\n",
       " 44: 'epoch_set_2',\n",
       " 45: 'epoch_set_2',\n",
       " 46: 'epoch_set_2',\n",
       " 47: 'epoch_set_2',\n",
       " 48: 'epoch_set_2',\n",
       " 49: 'epoch_set_7',\n",
       " 50: 'epoch_set_7',\n",
       " 51: 'epoch_set_2',\n",
       " 52: 'epoch_set_2',\n",
       " 53: 'epoch_set_7',\n",
       " 54: 'epoch_set_2',\n",
       " 55: 'epoch_set_1',\n",
       " 56: 'epoch_set_2',\n",
       " 57: 'epoch_set_2',\n",
       " 58: 'epoch_set_2',\n",
       " 59: 'epoch_set_2',\n",
       " 60: 'epoch_set_7',\n",
       " 61: 'epoch_set_2',\n",
       " 62: 'epoch_set_1',\n",
       " 63: 'epoch_set_2',\n",
       " 64: 'epoch_set_2',\n",
       " 65: 'epoch_set_2',\n",
       " 66: 'epoch_set_2',\n",
       " 67: 'epoch_set_7',\n",
       " 68: 'epoch_set_2',\n",
       " 69: 'epoch_set_2',\n",
       " 70: 'epoch_set_2',\n",
       " 71: 'epoch_set_2',\n",
       " 72: 'epoch_set_2',\n",
       " 73: 'epoch_set_2',\n",
       " 74: 'epoch_set_2',\n",
       " 75: 'epoch_set_2',\n",
       " 76: 'epoch_set_2',\n",
       " 77: 'epoch_set_2',\n",
       " 78: 'epoch_set_2',\n",
       " 79: 'epoch_set_2',\n",
       " 80: 'epoch_set_2',\n",
       " 81: 'epoch_set_2',\n",
       " 82: 'epoch_set_2',\n",
       " 83: 'epoch_set_2',\n",
       " 84: 'epoch_set_2',\n",
       " 85: 'epoch_set_2',\n",
       " 86: 'epoch_set_7',\n",
       " 87: 'epoch_set_2',\n",
       " 88: 'epoch_set_2',\n",
       " 89: 'epoch_set_2',\n",
       " 90: 'epoch_set_7',\n",
       " 91: 'epoch_set_1',\n",
       " 92: 'epoch_set_2',\n",
       " 93: 'epoch_set_2',\n",
       " 94: 'epoch_set_7',\n",
       " 95: 'epoch_set_2',\n",
       " 96: 'epoch_set_2',\n",
       " 97: 'epoch_set_2',\n",
       " 98: 'epoch_set_2',\n",
       " 99: 'epoch_set_2',\n",
       " 100: 'epoch_set_2',\n",
       " 101: 'epoch_set_2',\n",
       " 102: 'epoch_set_2',\n",
       " 103: 'epoch_set_2',\n",
       " 104: 'epoch_set_7',\n",
       " 105: 'epoch_set_2',\n",
       " 106: 'epoch_set_2',\n",
       " 107: 'epoch_set_2',\n",
       " 108: 'epoch_set_1',\n",
       " 109: 'epoch_set_2',\n",
       " 110: 'epoch_set_2',\n",
       " 111: 'epoch_set_2',\n",
       " 112: 'epoch_set_2',\n",
       " 113: 'epoch_set_1',\n",
       " 114: 'epoch_set_2',\n",
       " 115: 'epoch_set_7',\n",
       " 116: 'epoch_set_2',\n",
       " 117: 'epoch_set_2',\n",
       " 118: 'epoch_set_2',\n",
       " 119: 'epoch_set_2',\n",
       " 120: 'epoch_set_2',\n",
       " 121: 'epoch_set_2',\n",
       " 122: 'epoch_set_2',\n",
       " 123: 'epoch_set_2',\n",
       " 124: 'epoch_set_2',\n",
       " 125: 'epoch_set_2',\n",
       " 126: 'epoch_set_2',\n",
       " 127: 'epoch_set_2',\n",
       " 128: 'epoch_set_1',\n",
       " 129: 'epoch_set_2',\n",
       " 130: 'epoch_set_2',\n",
       " 131: 'epoch_set_2',\n",
       " 132: 'epoch_set_7',\n",
       " 133: 'epoch_set_2',\n",
       " 134: 'epoch_set_1',\n",
       " 135: 'epoch_set_2',\n",
       " 136: 'epoch_set_3',\n",
       " 137: 'epoch_set_2',\n",
       " 138: 'epoch_set_2',\n",
       " 139: 'epoch_set_2',\n",
       " 140: 'epoch_set_2',\n",
       " 141: 'epoch_set_2',\n",
       " 142: 'epoch_set_2',\n",
       " 143: 'epoch_set_2',\n",
       " 144: 'epoch_set_2',\n",
       " 145: 'epoch_set_2',\n",
       " 146: 'epoch_set_2',\n",
       " 147: 'epoch_set_2',\n",
       " 148: 'epoch_set_2',\n",
       " 149: 'epoch_set_2',\n",
       " 150: 'epoch_set_1',\n",
       " 151: 'epoch_set_2',\n",
       " 152: 'epoch_set_2',\n",
       " 153: 'epoch_set_7',\n",
       " 154: 'epoch_set_3',\n",
       " 155: 'epoch_set_2',\n",
       " 156: 'epoch_set_2',\n",
       " 157: 'epoch_set_2',\n",
       " 158: 'epoch_set_2',\n",
       " 159: 'epoch_set_1',\n",
       " 160: 'epoch_set_2',\n",
       " 161: 'epoch_set_1',\n",
       " 162: 'epoch_set_2',\n",
       " 163: 'epoch_set_2',\n",
       " 164: 'epoch_set_2',\n",
       " 165: 'epoch_set_2',\n",
       " 166: 'epoch_set_2',\n",
       " 167: 'epoch_set_2',\n",
       " 168: 'epoch_set_2',\n",
       " 169: 'epoch_set_2',\n",
       " 170: 'epoch_set_2',\n",
       " 171: 'epoch_set_2',\n",
       " 172: 'epoch_set_7',\n",
       " 173: 'epoch_set_2',\n",
       " 174: 'epoch_set_2',\n",
       " 175: 'epoch_set_2',\n",
       " 176: 'epoch_set_1',\n",
       " 177: 'epoch_set_2',\n",
       " 178: 'epoch_set_2',\n",
       " 179: 'epoch_set_2',\n",
       " 180: 'epoch_set_7',\n",
       " 181: 'epoch_set_2',\n",
       " 182: 'epoch_set_2',\n",
       " 183: 'epoch_set_2',\n",
       " 184: 'epoch_set_7',\n",
       " 185: 'epoch_set_2',\n",
       " 186: 'epoch_set_2',\n",
       " 187: 'epoch_set_7',\n",
       " 188: 'epoch_set_2',\n",
       " 189: 'epoch_set_2',\n",
       " 190: 'epoch_set_3',\n",
       " 191: 'epoch_set_2',\n",
       " 192: 'epoch_set_2',\n",
       " 193: 'epoch_set_2',\n",
       " 194: 'epoch_set_2',\n",
       " 195: 'epoch_set_2',\n",
       " 196: 'epoch_set_2',\n",
       " 197: 'epoch_set_2',\n",
       " 198: 'epoch_set_2',\n",
       " 199: 'epoch_set_1',\n",
       " 200: 'epoch_set_1',\n",
       " 201: 'epoch_set_2',\n",
       " 202: 'epoch_set_1',\n",
       " 203: 'epoch_set_2',\n",
       " 204: 'epoch_set_2',\n",
       " 205: 'epoch_set_7',\n",
       " 206: 'epoch_set_1',\n",
       " 207: 'epoch_set_2',\n",
       " 208: 'epoch_set_2',\n",
       " 209: 'epoch_set_3',\n",
       " 210: 'epoch_set_2',\n",
       " 211: 'epoch_set_2',\n",
       " 212: 'epoch_set_7',\n",
       " 213: 'epoch_set_2',\n",
       " 214: 'epoch_set_2',\n",
       " 215: 'epoch_set_3',\n",
       " 216: 'epoch_set_2',\n",
       " 217: 'epoch_set_2',\n",
       " 218: 'epoch_set_1',\n",
       " 219: 'epoch_set_2',\n",
       " 220: 'epoch_set_7',\n",
       " 221: 'epoch_set_2',\n",
       " 222: 'epoch_set_2',\n",
       " 223: 'epoch_set_2',\n",
       " 224: 'epoch_set_2',\n",
       " 225: 'epoch_set_2',\n",
       " 226: 'epoch_set_2',\n",
       " 227: 'epoch_set_7',\n",
       " 228: 'epoch_set_2',\n",
       " 229: 'epoch_set_2',\n",
       " 230: 'epoch_set_2',\n",
       " 231: 'epoch_set_2',\n",
       " 232: 'epoch_set_2',\n",
       " 233: 'epoch_set_2',\n",
       " 234: 'epoch_set_2',\n",
       " 235: 'epoch_set_9',\n",
       " 236: 'epoch_set_1',\n",
       " 237: 'epoch_set_3',\n",
       " 238: 'epoch_set_2',\n",
       " 239: 'epoch_set_2',\n",
       " 240: 'epoch_set_7',\n",
       " 241: 'epoch_set_2',\n",
       " 242: 'epoch_set_7',\n",
       " 243: 'epoch_set_2',\n",
       " 244: 'epoch_set_2',\n",
       " 245: 'epoch_set_2',\n",
       " 246: 'epoch_set_2',\n",
       " 247: 'epoch_set_1',\n",
       " 248: 'epoch_set_2',\n",
       " 249: 'epoch_set_2',\n",
       " 250: 'epoch_set_2',\n",
       " 251: 'epoch_set_2',\n",
       " 252: 'epoch_set_2',\n",
       " 253: 'epoch_set_7',\n",
       " 254: 'epoch_set_2',\n",
       " 255: 'epoch_set_3',\n",
       " 256: 'epoch_set_2',\n",
       " 257: 'epoch_set_3',\n",
       " 258: 'epoch_set_1',\n",
       " 259: 'epoch_set_1',\n",
       " 260: 'epoch_set_2',\n",
       " 261: 'epoch_set_2',\n",
       " 262: 'epoch_set_1',\n",
       " 263: 'epoch_set_2',\n",
       " 264: 'epoch_set_2',\n",
       " 265: 'epoch_set_1',\n",
       " 266: 'epoch_set_2',\n",
       " 267: 'epoch_set_2',\n",
       " 268: 'epoch_set_2',\n",
       " 269: 'epoch_set_2',\n",
       " 270: 'epoch_set_2',\n",
       " 271: 'epoch_set_2',\n",
       " 272: 'epoch_set_2',\n",
       " 273: 'epoch_set_2',\n",
       " 274: 'epoch_set_2',\n",
       " 275: 'epoch_set_2',\n",
       " 276: 'epoch_set_2',\n",
       " 277: 'epoch_set_2',\n",
       " 278: 'epoch_set_2',\n",
       " 279: 'epoch_set_2',\n",
       " 280: 'epoch_set_2',\n",
       " 281: 'epoch_set_1',\n",
       " 282: 'epoch_set_1',\n",
       " 283: 'epoch_set_2',\n",
       " 284: 'epoch_set_2',\n",
       " 285: 'epoch_set_7',\n",
       " 286: 'epoch_set_7',\n",
       " 287: 'epoch_set_2',\n",
       " 288: 'epoch_set_1',\n",
       " 289: 'epoch_set_7',\n",
       " 290: 'epoch_set_2',\n",
       " 291: 'epoch_set_7',\n",
       " 292: 'epoch_set_2',\n",
       " 293: 'epoch_set_2',\n",
       " 294: 'epoch_set_2',\n",
       " 295: 'epoch_set_2',\n",
       " 296: 'epoch_set_2',\n",
       " 297: 'epoch_set_7',\n",
       " 298: 'epoch_set_2',\n",
       " 299: 'epoch_set_2',\n",
       " 300: 'epoch_set_1',\n",
       " 301: 'epoch_set_2',\n",
       " 302: 'epoch_set_2',\n",
       " 303: 'epoch_set_7',\n",
       " 304: 'epoch_set_2',\n",
       " 305: 'epoch_set_2',\n",
       " 306: 'epoch_set_3',\n",
       " 307: 'epoch_set_2',\n",
       " 308: 'epoch_set_3',\n",
       " 309: 'epoch_set_2',\n",
       " 310: 'epoch_set_2',\n",
       " 311: 'epoch_set_7',\n",
       " 312: 'epoch_set_2',\n",
       " 313: 'epoch_set_7',\n",
       " 314: 'epoch_set_1',\n",
       " 315: 'epoch_set_3',\n",
       " 316: 'epoch_set_2',\n",
       " 317: 'epoch_set_2',\n",
       " 318: 'epoch_set_2',\n",
       " 319: 'epoch_set_2',\n",
       " 320: 'epoch_set_1',\n",
       " 321: 'epoch_set_2',\n",
       " 322: 'epoch_set_2',\n",
       " 323: 'epoch_set_2',\n",
       " 324: 'epoch_set_2',\n",
       " 325: 'epoch_set_2',\n",
       " 326: 'epoch_set_2',\n",
       " 327: 'epoch_set_2',\n",
       " 328: 'epoch_set_2',\n",
       " 329: 'epoch_set_2',\n",
       " 330: 'epoch_set_2',\n",
       " 331: 'epoch_set_2',\n",
       " 332: 'epoch_set_2',\n",
       " 333: 'epoch_set_2',\n",
       " 334: 'epoch_set_2',\n",
       " 335: 'epoch_set_2',\n",
       " 336: 'epoch_set_2',\n",
       " 337: 'epoch_set_2',\n",
       " 338: 'epoch_set_2',\n",
       " 339: 'epoch_set_7',\n",
       " 340: 'epoch_set_2',\n",
       " 341: 'epoch_set_2',\n",
       " 342: 'epoch_set_2',\n",
       " 343: 'epoch_set_2',\n",
       " 344: 'epoch_set_2',\n",
       " 345: 'epoch_set_2',\n",
       " 346: 'epoch_set_2',\n",
       " 347: 'epoch_set_2',\n",
       " 348: 'epoch_set_2',\n",
       " 349: 'epoch_set_2',\n",
       " 350: 'epoch_set_2',\n",
       " 351: 'epoch_set_2',\n",
       " 352: 'epoch_set_2',\n",
       " 353: 'epoch_set_2',\n",
       " 354: 'epoch_set_2',\n",
       " 355: 'epoch_set_2',\n",
       " 356: 'epoch_set_1',\n",
       " 357: 'epoch_set_2',\n",
       " 358: 'epoch_set_2',\n",
       " 359: 'epoch_set_2',\n",
       " 360: 'epoch_set_2',\n",
       " 361: 'epoch_set_2',\n",
       " 362: 'epoch_set_2',\n",
       " 363: 'epoch_set_2',\n",
       " 364: 'epoch_set_2',\n",
       " 365: 'epoch_set_2',\n",
       " 366: 'epoch_set_2',\n",
       " 367: 'epoch_set_1',\n",
       " 368: 'epoch_set_2',\n",
       " 369: 'epoch_set_2',\n",
       " 370: 'epoch_set_2',\n",
       " 371: 'epoch_set_2',\n",
       " 372: 'epoch_set_2',\n",
       " 373: 'epoch_set_2',\n",
       " 374: 'epoch_set_2',\n",
       " 375: 'epoch_set_2',\n",
       " 376: 'epoch_set_2',\n",
       " 377: 'epoch_set_2',\n",
       " 378: 'epoch_set_2',\n",
       " 379: 'epoch_set_2',\n",
       " 380: 'epoch_set_2',\n",
       " 381: 'epoch_set_2',\n",
       " 382: 'epoch_set_2',\n",
       " 383: 'epoch_set_2',\n",
       " 384: 'epoch_set_2',\n",
       " 385: 'epoch_set_2',\n",
       " 386: 'epoch_set_2',\n",
       " 387: 'epoch_set_1',\n",
       " 388: 'epoch_set_2',\n",
       " 389: 'epoch_set_2',\n",
       " 390: 'epoch_set_2',\n",
       " 391: 'epoch_set_2',\n",
       " 392: 'epoch_set_2',\n",
       " 393: 'epoch_set_2',\n",
       " 394: 'epoch_set_2',\n",
       " 395: 'epoch_set_7',\n",
       " 396: 'epoch_set_2',\n",
       " 397: 'epoch_set_7',\n",
       " 398: 'epoch_set_2',\n",
       " 399: 'epoch_set_2',\n",
       " 400: 'epoch_set_2',\n",
       " 401: 'epoch_set_2',\n",
       " 402: 'epoch_set_2',\n",
       " 403: 'epoch_set_7',\n",
       " 404: 'epoch_set_2',\n",
       " 405: 'epoch_set_1',\n",
       " 406: 'epoch_set_2',\n",
       " 407: 'epoch_set_2',\n",
       " 408: 'epoch_set_1',\n",
       " 409: 'epoch_set_1',\n",
       " 410: 'epoch_set_2',\n",
       " 411: 'epoch_set_2',\n",
       " 412: 'epoch_set_2',\n",
       " 413: 'epoch_set_2',\n",
       " 414: 'epoch_set_2',\n",
       " 415: 'epoch_set_2',\n",
       " 416: 'epoch_set_2',\n",
       " 417: 'epoch_set_2',\n",
       " 418: 'epoch_set_2',\n",
       " 419: 'epoch_set_2',\n",
       " 420: 'epoch_set_2',\n",
       " 421: 'epoch_set_3',\n",
       " 422: 'epoch_set_2',\n",
       " 423: 'epoch_set_7',\n",
       " 424: 'epoch_set_2',\n",
       " 425: 'epoch_set_2',\n",
       " 426: 'epoch_set_2',\n",
       " 427: 'epoch_set_2',\n",
       " 428: 'epoch_set_2',\n",
       " 429: 'epoch_set_2',\n",
       " 430: 'epoch_set_2',\n",
       " 431: 'epoch_set_2',\n",
       " 432: 'epoch_set_7',\n",
       " 433: 'epoch_set_7',\n",
       " 434: 'epoch_set_2',\n",
       " 435: 'epoch_set_2',\n",
       " 436: 'epoch_set_2',\n",
       " 437: 'epoch_set_2',\n",
       " 438: 'epoch_set_2',\n",
       " 439: 'epoch_set_2',\n",
       " 440: 'epoch_set_2',\n",
       " 441: 'epoch_set_2',\n",
       " 442: 'epoch_set_2',\n",
       " 443: 'epoch_set_2',\n",
       " 444: 'epoch_set_2',\n",
       " 445: 'epoch_set_2',\n",
       " 446: 'epoch_set_2',\n",
       " 447: 'epoch_set_3',\n",
       " 448: 'epoch_set_2',\n",
       " 449: 'epoch_set_2',\n",
       " 450: 'epoch_set_2',\n",
       " 451: 'epoch_set_2',\n",
       " 452: 'epoch_set_2',\n",
       " 453: 'epoch_set_2',\n",
       " 454: 'epoch_set_2',\n",
       " 455: 'epoch_set_2',\n",
       " 456: 'epoch_set_1',\n",
       " 457: 'epoch_set_2',\n",
       " 458: 'epoch_set_2',\n",
       " 459: 'epoch_set_2',\n",
       " 460: 'epoch_set_2',\n",
       " 461: 'epoch_set_2',\n",
       " 462: 'epoch_set_2',\n",
       " 463: 'epoch_set_2',\n",
       " 464: 'epoch_set_1',\n",
       " 465: 'epoch_set_2',\n",
       " 466: 'epoch_set_2',\n",
       " 467: 'epoch_set_3',\n",
       " 468: 'epoch_set_1',\n",
       " 469: 'epoch_set_2',\n",
       " 470: 'epoch_set_2',\n",
       " 471: 'epoch_set_2',\n",
       " 472: 'epoch_set_2',\n",
       " 473: 'epoch_set_7',\n",
       " 474: 'epoch_set_2',\n",
       " 475: 'epoch_set_2',\n",
       " 476: 'epoch_set_7',\n",
       " 477: 'epoch_set_2',\n",
       " 478: 'epoch_set_2',\n",
       " 479: 'epoch_set_2',\n",
       " 480: 'epoch_set_2',\n",
       " 481: 'epoch_set_2',\n",
       " 482: 'epoch_set_2',\n",
       " 483: 'epoch_set_2',\n",
       " 484: 'epoch_set_2',\n",
       " 485: 'epoch_set_2',\n",
       " 486: 'epoch_set_2',\n",
       " 487: 'epoch_set_2',\n",
       " 488: 'epoch_set_1',\n",
       " 489: 'epoch_set_2',\n",
       " 490: 'epoch_set_2',\n",
       " 491: 'epoch_set_2',\n",
       " 492: 'epoch_set_2',\n",
       " 493: 'epoch_set_2',\n",
       " 494: 'epoch_set_2',\n",
       " 495: 'epoch_set_2',\n",
       " 496: 'epoch_set_2',\n",
       " 497: 'epoch_set_2',\n",
       " 498: 'epoch_set_2'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_ensemble_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opt_es_id\n",
       "epoch_set_2    5586\n",
       "epoch_set_7     602\n",
       "epoch_set_1     574\n",
       "epoch_set_3     210\n",
       "epoch_set_9      14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df[\"opt_es_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>intent</th>\n",
       "      <th>output_sequence</th>\n",
       "      <th>input_sequence</th>\n",
       "      <th>idx</th>\n",
       "      <th>cluster</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>rouge</th>\n",
       "      <th>opt_es_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38152389</td>\n",
       "      <td>Coalesce values from 2 columns into a single c...</td>\n",
       "      <td>combine values from column 'b' and column 'a' ...</td>\n",
       "      <td>df['c'] = np.where(df['a'].isnull, df['b'], df...</td>\n",
       "      <td>2736</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2180, 3292, 71, 3546, 273, 1130, 18, 6051,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 14082, 924, 628, 1057, 296, 70, 11, 471, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>epoch_set_0</td>\n",
       "      <td>Update c column</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>epoch_set_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6407780</td>\n",
       "      <td>How to extract data from JSON Object in Python?</td>\n",
       "      <td>extract data field 'bar' from json object</td>\n",
       "      <td>json.loads('{\"foo\": 42, \"bar\": \"baz\"}')['bar']</td>\n",
       "      <td>1143</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1977, 18, 17135, 2668, 16711, 11351, 6877,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 8004, 501, 652, 296, 3215, 11, 628, 1163, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>epoch_set_0</td>\n",
       "      <td>JSON. parse returns 42</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6696027</td>\n",
       "      <td>split elements of a list in python</td>\n",
       "      <td>split strings in list `l` on the first occurri...</td>\n",
       "      <td>[i.split('\\t', 1)[0] for i in l]</td>\n",
       "      <td>1170</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 63, 77, 18, 4939, 2668, 64, 88, 2187, 404,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 4939, 2064, 316, 666, 1375, 80, 68, 603, 3...</td>\n",
       "      <td>2</td>\n",
       "      <td>epoch_set_0</td>\n",
       "      <td>Split the string into a list of strings</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179369</td>\n",
       "      <td>How do I abort the execution of a Python script?</td>\n",
       "      <td>abort the execution of the script using messag...</td>\n",
       "      <td>sys.exit('aa! errors!')</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 9499, 18, 8593, 2668, 7598, 5, 1334, 5124,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 18623, 326, 4588, 434, 326, 2728, 1450, 88...</td>\n",
       "      <td>3</td>\n",
       "      <td>epoch_set_0</td>\n",
       "      <td>Exit with an error message</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2823472</td>\n",
       "      <td>Is there a method that tells my program to quit?</td>\n",
       "      <td>quit program</td>\n",
       "      <td>sys.exit(0)</td>\n",
       "      <td>672</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 9499, 18, 8593, 12, 20, 13, 2, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 27176, 5402, 2, -100, -100, -100, -100, -1...</td>\n",
       "      <td>4</td>\n",
       "      <td>epoch_set_0</td>\n",
       "      <td>Exit the program with status 0.</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1093322</td>\n",
       "      <td>check what version of Python is running</td>\n",
       "      <td>check python version</td>\n",
       "      <td>sys.version_info</td>\n",
       "      <td>415</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 9499, 18, 1589, 67, 1376, 2, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1893, 5790, 1177, 2, -100, -100, -100, -10...</td>\n",
       "      <td>494</td>\n",
       "      <td>cluster_set_6</td>\n",
       "      <td>get the version of sys. version_info</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>14406214</td>\n",
       "      <td>Moving x-axis to the top of a plot in matplotlib</td>\n",
       "      <td>move x-axis to the top of a plot `ax`</td>\n",
       "      <td>ax.xaxis.tick_top()</td>\n",
       "      <td>1830</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 651, 18, 92, 4890, 18, 6470, 67, 3669, 143...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 8501, 619, 17, 4890, 358, 326, 1760, 434, ...</td>\n",
       "      <td>495</td>\n",
       "      <td>cluster_set_6</td>\n",
       "      <td>tick the top of the axis</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>17071871</td>\n",
       "      <td>Select rows from a DataFrame based on values i...</td>\n",
       "      <td>select rows from a dataframe `df` whose value ...</td>\n",
       "      <td>df.loc[~df['column_name'].isin(some_values)]</td>\n",
       "      <td>2026</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2180, 18, 1829, 63, 98, 2180, 3292, 2827, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 4025, 2595, 628, 279, 12170, 1375, 2180, 6...</td>\n",
       "      <td>496</td>\n",
       "      <td>cluster_set_6</td>\n",
       "      <td>remove values from a dictionary `df` where the...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5137497</td>\n",
       "      <td>Find current directory and file's directory</td>\n",
       "      <td>get the canonical path of file `path`</td>\n",
       "      <td>os.path.realpath(path)</td>\n",
       "      <td>1035</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 538, 18, 803, 18, 7688, 803, 12, 803, 13, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 588, 326, 7378, 589, 434, 585, 1375, 803, ...</td>\n",
       "      <td>497</td>\n",
       "      <td>cluster_set_6</td>\n",
       "      <td>get the real path of a path</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1712227</td>\n",
       "      <td>get the size of a list</td>\n",
       "      <td>get the size of object `items`</td>\n",
       "      <td>items.__len__()</td>\n",
       "      <td>489</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 3319, 16186, 1897, 972, 1435, 2, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 588, 326, 963, 434, 733, 1375, 3319, 68, 2...</td>\n",
       "      <td>498</td>\n",
       "      <td>cluster_set_6</td>\n",
       "      <td>get the number of items in dictionary `items`</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>epoch_set_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6986 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_id                                             intent  \\\n",
       "0       38152389  Coalesce values from 2 columns into a single c...   \n",
       "1        6407780    How to extract data from JSON Object in Python?   \n",
       "2        6696027                 split elements of a list in python   \n",
       "3         179369   How do I abort the execution of a Python script?   \n",
       "4        2823472   Is there a method that tells my program to quit?   \n",
       "..           ...                                                ...   \n",
       "494      1093322            check what version of Python is running   \n",
       "495     14406214   Moving x-axis to the top of a plot in matplotlib   \n",
       "496     17071871  Select rows from a DataFrame based on values i...   \n",
       "497      5137497        Find current directory and file's directory   \n",
       "498      1712227                             get the size of a list   \n",
       "\n",
       "                                       output_sequence  \\\n",
       "0    combine values from column 'b' and column 'a' ...   \n",
       "1            extract data field 'bar' from json object   \n",
       "2    split strings in list `l` on the first occurri...   \n",
       "3    abort the execution of the script using messag...   \n",
       "4                                         quit program   \n",
       "..                                                 ...   \n",
       "494                               check python version   \n",
       "495              move x-axis to the top of a plot `ax`   \n",
       "496  select rows from a dataframe `df` whose value ...   \n",
       "497              get the canonical path of file `path`   \n",
       "498                     get the size of object `items`   \n",
       "\n",
       "                                        input_sequence   idx  cluster  \\\n",
       "0    df['c'] = np.where(df['a'].isnull, df['b'], df...  2736        3   \n",
       "1       json.loads('{\"foo\": 42, \"bar\": \"baz\"}')['bar']  1143        4   \n",
       "2                     [i.split('\\t', 1)[0] for i in l]  1170        7   \n",
       "3                              sys.exit('aa! errors!')    81        4   \n",
       "4                                          sys.exit(0)   672        4   \n",
       "..                                                 ...   ...      ...   \n",
       "494                                   sys.version_info   415        4   \n",
       "495                                ax.xaxis.tick_top()  1830        4   \n",
       "496       df.loc[~df['column_name'].isin(some_values)]  2026        3   \n",
       "497                             os.path.realpath(path)  1035        9   \n",
       "498                                    items.__len__()   489        4   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0    [1, 2180, 3292, 71, 3546, 273, 1130, 18, 6051,...   \n",
       "1    [1, 1977, 18, 17135, 2668, 16711, 11351, 6877,...   \n",
       "2    [1, 63, 77, 18, 4939, 2668, 64, 88, 2187, 404,...   \n",
       "3    [1, 9499, 18, 8593, 2668, 7598, 5, 1334, 5124,...   \n",
       "4    [1, 9499, 18, 8593, 12, 20, 13, 2, 0, 0, 0, 0,...   \n",
       "..                                                 ...   \n",
       "494  [1, 9499, 18, 1589, 67, 1376, 2, 0, 0, 0, 0, 0...   \n",
       "495  [1, 651, 18, 92, 4890, 18, 6470, 67, 3669, 143...   \n",
       "496  [1, 2180, 18, 1829, 63, 98, 2180, 3292, 2827, ...   \n",
       "497  [1, 538, 18, 803, 18, 7688, 803, 12, 803, 13, ...   \n",
       "498  [1, 3319, 16186, 1897, 972, 1435, 2, 0, 0, 0, ...   \n",
       "\n",
       "                                    attention_mask  \\\n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]   \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                             ...   \n",
       "494  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "495  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]   \n",
       "496  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "497  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]   \n",
       "498  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                labels   id       model_id  \\\n",
       "0    [1, 14082, 924, 628, 1057, 296, 70, 11, 471, 1...    0    epoch_set_0   \n",
       "1    [1, 8004, 501, 652, 296, 3215, 11, 628, 1163, ...    1    epoch_set_0   \n",
       "2    [1, 4939, 2064, 316, 666, 1375, 80, 68, 603, 3...    2    epoch_set_0   \n",
       "3    [1, 18623, 326, 4588, 434, 326, 2728, 1450, 88...    3    epoch_set_0   \n",
       "4    [1, 27176, 5402, 2, -100, -100, -100, -100, -1...    4    epoch_set_0   \n",
       "..                                                 ...  ...            ...   \n",
       "494  [1, 1893, 5790, 1177, 2, -100, -100, -100, -10...  494  cluster_set_6   \n",
       "495  [1, 8501, 619, 17, 4890, 358, 326, 1760, 434, ...  495  cluster_set_6   \n",
       "496  [1, 4025, 2595, 628, 279, 12170, 1375, 2180, 6...  496  cluster_set_6   \n",
       "497  [1, 588, 326, 7378, 589, 434, 585, 1375, 803, ...  497  cluster_set_6   \n",
       "498  [1, 588, 326, 963, 434, 733, 1375, 3319, 68, 2...  498  cluster_set_6   \n",
       "\n",
       "                                            prediction     rouge    opt_es_id  \n",
       "0                                      Update c column  0.200000  epoch_set_3  \n",
       "1                               JSON. parse returns 42  0.181818  epoch_set_2  \n",
       "2              Split the string into a list of strings  0.333333  epoch_set_2  \n",
       "3                           Exit with an error message  0.266667  epoch_set_2  \n",
       "4                      Exit the program with status 0.  0.250000  epoch_set_2  \n",
       "..                                                 ...       ...          ...  \n",
       "494               get the version of sys. version_info  0.200000  epoch_set_2  \n",
       "495                           tick the top of the axis  0.500000  epoch_set_2  \n",
       "496  remove values from a dictionary `df` where the...  0.533333  epoch_set_2  \n",
       "497                        get the real path of a path  0.714286  epoch_set_2  \n",
       "498      get the number of items in dictionary `items`  0.571429  epoch_set_2  \n",
       "\n",
       "[6986 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
