{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##########  DEPENDECIES ############\n",
    "#####################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm # type: ignore\n",
    "from datetime import date\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import utils.prep as pr\n",
    "import utils.eval as ev\n",
    "import utils.inference as infer\n",
    "from utils.sampling import create_splits, prep_cv_validation\n",
    "from utils.training import cv_cluster_set, cv_training_epochs_sets, test_cluster_set\n",
    "from utils.training import results_dict_todf, cv_step_2, full_step_2, test_training_epochs_sets\n",
    "from utils.inference import meta_predict, create_ensemble_map, ensemble_compute\n",
    "\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "\n",
    "#####################################\n",
    "############  CONSTANTS #############\n",
    "#####################################\n",
    "\n",
    "RS = 42\n",
    "BATCH_SIZE = 16\n",
    "DECODER_LENGTH = 15\n",
    "ENCODER_LENGTH = 15\n",
    "MODEL_NAME = \"Salesforce/codet5-base-multi-sum\"\n",
    "\n",
    "FULL_TRAIN_ARGS = {\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DECODER_LENGTH\": DECODER_LENGTH,\n",
    "    \"ENCODER_LENGTH\": ENCODER_LENGTH,\n",
    "    \"SEQ_TRAINER_ARGS\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": [0, 1, 2, 5, 10],\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 4,\n",
    "        \"learning_rate\": 6e-6,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"label_smoothing_factor\": 0.1,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"logging_steps\": 100,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"save_strategy\": \"no\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"load_best_model_at_end\": False,\n",
    "        \"output_dir\" : 'reports/results',\n",
    "        \"logging_dir\" : \"reports/logs\",\n",
    "    },\n",
    "}\n",
    "\n",
    "experiment_config = {\n",
    "    \"DATA_STR\" : \"20240721\",\n",
    "    \"RS\" : RS,\n",
    "    \"DRIFT_TYPE\" : \"sudden\",\n",
    "    \"NFOLD\" : 3,\n",
    "    \"FULL_TRAIN_ARGS\" : FULL_TRAIN_ARGS,\n",
    "    \"MODEL_NAME\" : MODEL_NAME,\n",
    "    \"CLUSTER_EPOCHS\" : 2,\n",
    "}\n",
    "experiment_config[\"ANALYSIS_POSTFIX\"] = f\"mined_{experiment_config['DRIFT_TYPE']}_{str(date.today())}\"\n",
    "experiment_config[\"FULL_TRAIN_ARGS\"][\"output_dir\"] += \"/\" + experiment_config[\"ANALYSIS_POSTFIX\"] \n",
    "experiment_config[\"FULL_TRAIN_ARGS\"][\"logging_dir\"] += \"/\" + experiment_config[\"ANALYSIS_POSTFIX\"] \n",
    "\n",
    "if not os.path.exists(experiment_config[\"FULL_TRAIN_ARGS\"][\"logging_dir\"]):\n",
    "    os.mkdir(experiment_config[\"FULL_TRAIN_ARGS\"][\"logging_dir\"])\n",
    "\n",
    "if not os.path.exists(experiment_config[\"FULL_TRAIN_ARGS\"][\"output_dir\"]):\n",
    "    os.mkdir(experiment_config[\"FULL_TRAIN_ARGS\"][\"output_dir\"])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(experiment_config[\"MODEL_NAME\"], skip_special_tokens=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(experiment_config[\"MODEL_NAME\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conala data. Preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  (7942, 11)\n",
      "Test Data:  (2058, 11)\n",
      "Train Data: Cluster cluster\n",
      "2    3545\n",
      "3    2094\n",
      "1    1627\n",
      "0     408\n",
      "4     268\n",
      "Name: count, dtype: int64\n",
      "Test Data: Cluster cluster\n",
      "4    1732\n",
      "3     149\n",
      "2     112\n",
      "1      57\n",
      "0       8\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd027d875844b418cb249c6b25826e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2058 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f446ba7a0bb64a1ea5ff7d4e60018938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2058 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e65fd60657a4675b638f2c9a081f938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2058 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n"
     ]
    }
   ],
   "source": [
    "sampling_dict = create_splits(experiment_config=experiment_config, tokenizer=tokenizer, test=False)\n",
    "train_dataset, test_data, test_df = sampling_dict[\"train_data\"], sampling_dict[\"test_data\"], sampling_dict[\"test_df\"]\n",
    "\n",
    "splits, questions_list = prep_cv_validation(train_dataset=train_dataset, \n",
    "                            experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4233ef6b31c4337a0999f7f19b288b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7951 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7f84edbace435da08093e09c0f3846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7951 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a09a789ce04ef6ac8fec848dd86f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e154f5b319434f378b2b4bbd3e169499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2b1201e53948c9a9fb231714d12526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_results = cv_training_epochs_sets(experiment_config=experiment_config,\n",
    "                            splits=splits,\n",
    "                            questions_list=questions_list,\n",
    "                            train_dataset=train_dataset,\n",
    "                            tokenizer=tokenizer)\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_fold_epoch_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(fold_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_fold_epoch_set.pickle', 'rb') as handle:\n",
    "   fold_results = pickle.load(handle)\n",
    "   \n",
    "for cluster_idx in [1, 4, 3]:\n",
    "    fold_results = cv_cluster_set(experiment_config=experiment_config,\n",
    "                                            splits=splits,\n",
    "                                            questions_list=questions_list,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            tokenizer=tokenizer,\n",
    "                                            fold_results=fold_results,\n",
    "                                            cluster_id=cluster_idx)\n",
    "\n",
    "cv_df = results_dict_todf(fold_results)\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_step1.pickle', 'wb') as handle:\n",
    "    pickle.dump(cv_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean\")\n",
    "print(cv_df.groupby([\"model_set\"])[\"rouge\"].mean())\n",
    "\n",
    "print(\"STD\")\n",
    "print(cv_df.groupby(\"model_set\")[\"rouge\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Learn performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########## LOAD CV RESULTS\n",
    "\n",
    "import pickle\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_step1.pickle', 'rb') as handle:\n",
    "    cv_df = pickle.load(handle)\n",
    "\n",
    "########## RUN STEP 2 ON CV\n",
    "\n",
    "cv_df, model_results = cv_step_2(experiment_config=experiment_config, cv_df=cv_df)\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/s2_model_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(cv_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO SAVE THE VECTORIZER AND STEP 2 MODELS\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_results.pickle', 'rb') as handle:\n",
    "    cv_df = pickle.load(handle)\n",
    "\n",
    "\n",
    "print(\"Mean\")\n",
    "print(cv_df.groupby([\"model_set\"])[\"rouge\"].mean())\n",
    "\n",
    "print(\"STD\")\n",
    "print(cv_df.groupby(\"model_set\")[\"rouge\"].std())\n",
    "\n",
    "\n",
    "full_step_2(cv_df=cv_df, \n",
    "            experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dict = create_splits(experiment_config=experiment_config, tokenizer=tokenizer, test=True)\n",
    "train_dataset, test_data, test_df = sampling_dict[\"train_data\"], sampling_dict[\"test_data\"], sampling_dict[\"test_df\"]\n",
    "\n",
    "splits, questions_list = prep_cv_validation(train_dataset=train_dataset, \n",
    "                            experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/cv_results.pickle\", \"rb\") as handle:\n",
    "    cv_resutls = pickle.load(handle)\n",
    "\n",
    "base_models_list = list(cv_resutls.model_set.unique())\n",
    "base_models_list.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_preds_df = meta_predict(experiment_config=experiment_config, \n",
    "                    test_df=test_df,\n",
    "                    base_models_names=base_models_list,\n",
    "                    t_models=[\"svm\", \"catboost\"])\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/test_step2.pickle', 'wb') as handle:\n",
    "    pickle.dump(meta_preds_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/test_step2.pickle', 'rb') as handle:\n",
    "    meta_preds_df = pickle.load(handle)\n",
    "    \n",
    "meta_preds_df.groupby(\"model_set\").svm_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_ensemble_map, ensemble_val_estim = create_ensemble_map(meta_preds_df=meta_preds_df, \n",
    "                                                                t_model_name=\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result_df = test_training_epochs_sets(experiment_config=experiment_config,\n",
    "                            test_df=test_df,\n",
    "                            test_data=test_data,\n",
    "                            train_data=train_dataset,\n",
    "                            tokenizer=tokenizer)\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/test_epoch_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_result_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/test_epoch_set.pickle', 'rb') as handle:\n",
    "   test_result_df = pickle.load(handle)\n",
    "\n",
    "test_result_df = test_result_df.rename(columns={\"epoch_set\": \"model_set\"})\n",
    "\n",
    "for cluster_idx in [1, 4, 3]:\n",
    "    test_result_dict = test_cluster_set(experiment_config=experiment_config,\n",
    "                                    test_df=test_df,\n",
    "                                    test_data=test_data,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    results_df=test_result_df,\n",
    "                                    cluster_id=cluster_idx)\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/test_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_result_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENSEMBLE COMPUTE\n",
    "test_result_df = ensemble_compute(test_result_df=test_result_df,\n",
    "                                  optimal_ensemble_map=optimal_ensemble_map)\n",
    "\n",
    "########## ROUGE PER SETTING\n",
    "\n",
    "print(\"Mean\")\n",
    "print(test_result_df.groupby(\"model_set\")[\"rouge\"].mean())\n",
    "\n",
    "print(\"STD\")\n",
    "print(test_result_df.groupby(\"model_set\")[\"rouge\"].std())\n",
    "\n",
    "test_result_df.opt_es_id.value_counts()\n",
    "\n",
    "with open(f'reports/results/{experiment_config[\"ANALYSIS_POSTFIX\"]}/test_results_full.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_result_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
