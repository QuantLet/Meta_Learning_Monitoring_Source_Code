{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "##########  DEPENDECIES ############\n",
    "#####################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm # type: ignore\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from sklearn.model_selection import KFold # type: ignore\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import utils.prep as pr\n",
    "import utils.eval as ev\n",
    "import utils.inference as infer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import torch\n",
    "#####################################\n",
    "############  CONSTANTS #############\n",
    "#####################################\n",
    "RS = 42\n",
    "\n",
    "MODEL = \"CodeT5\"\n",
    "BATCH_SIZE = 15\n",
    "DECODER_LENGTH = 20\n",
    "ENCODER_LENGTH = 30\n",
    "\n",
    "FULL_TRAIN_ARGS = {\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DECODER_LENGTH\": DECODER_LENGTH,\n",
    "    \"ENCODER_LENGTH\": ENCODER_LENGTH,\n",
    "    \"MODEL\": MODEL,\n",
    "    \"SEQ_TRAINER_ARGS\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": [0, 1, 2, 3, 4, 8, 10, 16],\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 4,\n",
    "        \"learning_rate\": 6e-6,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"label_smoothing_factor\": 0.1,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"logging_steps\": 100,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"save_strategy\": \"no\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"load_best_model_at_end\": False,\n",
    "    },\n",
    "}\n",
    "FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"output_dir\"] = f'reports/results'\n",
    "FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"logging_dir\"] = f'reports/logs'\n",
    "\n",
    "model_name=\"Salesforce/codet5-base-multi-sum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conala data. Preprocessing. Sampling as in the paper (further, random sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_STR = 20240721\n",
    "SEMANTIC_DRIFT = True\n",
    "dataset = pd.read_csv(f\"../data/processed/conala/{DATE_STR}/conala_mined_clustered.csv\")#.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  (3294, 11)\n",
      "Test Data:  (1706, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 3294/3294 [00:00<00:00, 111294.90 examples/s]\n",
      "Filter: 100%|██████████| 3294/3294 [00:00<00:00, 38855.81 examples/s]\n",
      "Map: 100%|██████████| 3294/3294 [00:01<00:00, 1942.66 examples/s]\n",
      "Filter: 100%|██████████| 1706/1706 [00:00<00:00, 130971.24 examples/s]\n",
      "Filter: 100%|██████████| 1706/1706 [00:00<00:00, 48422.45 examples/s]\n",
      "Map: 100%|██████████| 1706/1706 [00:00<00:00, 2532.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "if SEMANTIC_DRIFT:\n",
    "    dataset_4_cl = dataset[dataset.cluster==4].sample(n=1000, random_state=RS)\n",
    "    dataset_non_4_cl = dataset[dataset.cluster!=4].sample(n=4000, random_state=RS)\n",
    "\n",
    "    qids_4_cl = sorted(dataset_4_cl.question_id.unique())\n",
    "    train_idx_4_cl, test_idx_4_cl = qids_4_cl[int(len(qids_4_cl)*0.9):], qids_4_cl[:int(len(qids_4_cl)*0.9)]\n",
    "\n",
    "    qids_non4_cl = sorted(dataset_non_4_cl.question_id.unique())\n",
    "    train_idx_non4_cl, test_idx_non4_cl = qids_non4_cl[:int(len(qids_non4_cl)*0.8)], qids_non4_cl[int(len(qids_non4_cl)*0.8):]\n",
    "\n",
    "    train_dataset_4cl = dataset_4_cl[dataset_4_cl.question_id.isin(train_idx_4_cl)]\n",
    "    test_dataset_4cl = dataset_4_cl[dataset_4_cl.question_id.isin(test_idx_4_cl)]\n",
    "\n",
    "    train_dataset_non4cl = dataset_non_4_cl[dataset_non_4_cl.question_id.isin(train_idx_non4_cl)]\n",
    "    test_dataset_non4cl = dataset_non_4_cl[dataset_non_4_cl.question_id.isin(test_idx_non4_cl)]\n",
    "\n",
    "    train_dataset = pd.concat([train_dataset_4cl, train_dataset_non4cl], axis=0).sample(frac=1, random_state=RS).reset_index(drop=True)\n",
    "    test_dataset = pd.concat([test_dataset_4cl, test_dataset_non4cl], axis=0).sample(frac=1, random_state=RS).reset_index(drop=True)\n",
    "    \n",
    "else:\n",
    "    qids = sorted(dataset.question_id.unique())\n",
    "    train_idx, test_idx = qids[:int(len(qids)*0.8)], qids[int(len(qids)*0.8):]\n",
    "    train_dataset = dataset[dataset.question_id.isin(train_idx)]\n",
    "    test_dataset = dataset[dataset.question_id.isin(test_idx)]\n",
    "\n",
    "\n",
    "print(\"Train Data: \", train_dataset.shape)\n",
    "print(\"Test Data: \", test_dataset.shape)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset.sample(frac=1, random_state=RS).reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_dataset.sample(frac=1, random_state=RS).reset_index(drop=True))\n",
    "\n",
    "train_data = pr.preprocess_dataset(train_dataset, tokenizer=tokenizer, intent_colum_name=\"intent\")\n",
    "test_data = pr.preprocess_dataset(test_dataset, tokenizer=tokenizer, intent_colum_name=\"intent\")\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df[\"id\"] = test_df.index\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_perf(X, model): \n",
    "\n",
    "    with open(f'./models/reg_{model}_mined.pkl','rb') as f:\n",
    "            reg = pickle.load(f)\n",
    "\n",
    "    y_pred = reg.predict(X)\n",
    "    y_pred[y_pred<0] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "catboost\n"
     ]
    }
   ],
   "source": [
    "### Step 1. PREDICT PERFORMANCE\n",
    "\n",
    "# TRAIN ON ALL PREDICTIONS AT ONCE\n",
    "\n",
    "t_models = [\"svm\", \"catboost\"]\n",
    "\n",
    "for epoch_i, epoch_set in enumerate(sorted(FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"])):\n",
    "\n",
    "    set_df = test_df.copy()\n",
    "    set_df[\"epoch_set\"] = epoch_set\n",
    "    # Prepare the input data\n",
    "    with open(\"./models/mined_vectorizer.pkl\", \"rb\") as file:\n",
    "        vectorizer = pickle.load(file)\n",
    "\n",
    "    if epoch_set==0:\n",
    "        meta_preds_df = set_df.copy()\n",
    "    else: \n",
    "        meta_preds_df = pd.concat([meta_preds_df, set_df])\n",
    "         \n",
    "X_test_tfidf = vectorizer.transform(meta_preds_df.loc[:, \"input_sequence\"])\n",
    "X_test_column_sparse = pd.get_dummies(meta_preds_df.loc[:, \"epoch_set\"], sparse=True).sparse.to_coo().tocsr()\n",
    "X_test = hstack([X_test_column_sparse, X_test_tfidf])\n",
    "#y_test = test_df.loc[:, \"rouge\"]\n",
    "\n",
    "models_preds = []\n",
    "for model in t_models:\n",
    "    print(model)\n",
    "    meta_preds_df[f\"{model}_preds\"] = pred_perf(X_test, model)\n",
    "\n",
    "meta_preds_df = meta_preds_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch_set\n",
       "0     0.115100\n",
       "1     0.227082\n",
       "2     0.248756\n",
       "3     0.263008\n",
       "4     0.262828\n",
       "8     0.266490\n",
       "10    0.263008\n",
       "16    0.266307\n",
       "Name: catboost_preds, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_preds_df.groupby(\"epoch_set\").catboost_preds.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_index = meta_preds_df.groupby(\"id\")[\"catboost_preds\"].idxmax()\n",
    "optimal_ensemble = meta_preds_df.iloc[models_index][[\"id\", \"epoch_set\"]]\n",
    "optimal_ensemble_map = dict(zip(optimal_ensemble.id, optimal_ensemble.epoch_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 0\n",
      "TRAINING EPOCHS 0\n",
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 1\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL Salesforce/codet5-base-multi-sum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='824' max='824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [824/824 03:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.358600</td>\n",
       "      <td>4.853644</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>14.375100</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.183300</td>\n",
       "      <td>19422</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 2\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL ./models/1_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='824' max='824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [824/824 03:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.760100</td>\n",
       "      <td>4.724127</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>14.140700</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.157000</td>\n",
       "      <td>18991</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 3\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL ./models/2_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='824' max='824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [824/824 03:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.535300</td>\n",
       "      <td>4.685239</td>\n",
       "      <td>0.257700</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>14.087900</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.152400</td>\n",
       "      <td>18915</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 4\n",
      "TRAINING EPOCHS 1\n",
      "LOADING MODEL ./models/3_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='824' max='824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [824/824 03:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.351700</td>\n",
       "      <td>4.682157</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>14.075000</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.149300</td>\n",
       "      <td>18864</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 8\n",
      "TRAINING EPOCHS 4\n",
      "LOADING MODEL ./models/4_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3296' max='3296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3296/3296 12:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.169200</td>\n",
       "      <td>4.643461</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.225100</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>14.106100</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.151600</td>\n",
       "      <td>18902</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.485300</td>\n",
       "      <td>4.590150</td>\n",
       "      <td>0.263700</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>14.339400</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>19368</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.394300</td>\n",
       "      <td>4.575965</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.229300</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>14.157700</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.158900</td>\n",
       "      <td>19023</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.343200</td>\n",
       "      <td>4.575565</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>14.232700</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.167800</td>\n",
       "      <td>19169</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 10\n",
      "TRAINING EPOCHS 2\n",
      "LOADING MODEL ./models/8_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1648' max='1648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1648/1648 06:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.828700</td>\n",
       "      <td>4.651332</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>14.017600</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.141100</td>\n",
       "      <td>18730</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.126800</td>\n",
       "      <td>4.618661</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>13.913800</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.127900</td>\n",
       "      <td>18513</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH SET 16\n",
      "TRAINING EPOCHS 6\n",
      "LOADING MODEL ./models/10_epoch_set\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4944' max='4944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4944/4944 17:57, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.553000</td>\n",
       "      <td>4.725651</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>13.837600</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.120100</td>\n",
       "      <td>18385</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.953900</td>\n",
       "      <td>4.622912</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>14.228600</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.160700</td>\n",
       "      <td>19052</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.057900</td>\n",
       "      <td>4.598320</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>13.980100</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.136800</td>\n",
       "      <td>18659</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.065700</td>\n",
       "      <td>4.589098</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.222300</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>14.110800</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.146000</td>\n",
       "      <td>18811</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.047000</td>\n",
       "      <td>4.589703</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>14.065100</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.143500</td>\n",
       "      <td>18770</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.030600</td>\n",
       "      <td>4.588837</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>14.052200</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>18760</td>\n",
       "      <td>16414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/utils/import_utils.py:616: FutureWarning: `torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.\n",
      "  return dynamo.is_compiling()\n",
      "/home/RDC/zinovyee.hub/.conda/envs/ensemble/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "latest_run_epoch = 0\n",
    "\n",
    "for epoch_i, epoch_set in enumerate(sorted(FULL_TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"])):\n",
    "\n",
    "    set_df = test_df.copy()\n",
    "    print(f\"TRAINING EPOCH SET {epoch_set}\")\n",
    "\n",
    "    TRAIN_ARGS = copy.deepcopy(FULL_TRAIN_ARGS)\n",
    "    MODEL_PATH = f\"./models/{epoch_set}_epoch_set\"\n",
    "    \n",
    "\n",
    "    results[epoch_set] = {}\n",
    "\n",
    "    if epoch_set > 1: \n",
    "        TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = epoch_set - latest_run_epoch\n",
    "    else:\n",
    "        TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"] = epoch_set\n",
    "    \n",
    "    print(f'TRAINING EPOCHS {TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"][\"num_train_epochs\"]}')\n",
    "\n",
    "    if epoch_set > 1: \n",
    "        model_name = f\"./models/{latest_run_epoch}_epoch_set\"\n",
    "\n",
    "    print(f\"LOADING MODEL {model_name}\")\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    compute_metrics = ev.compute_metric_with_params(tokenizer) \n",
    "\n",
    "    if not os.path.exists(f'reports/'): \n",
    "        os.mkdir(f'reports/')\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "            **TRAIN_ARGS[\"SEQ_TRAINER_ARGS\"],\n",
    "        )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    if epoch_set!=0:\n",
    "        trainer.train()\n",
    "\n",
    "    text = list(test_df[\"input_sequence\"].values)\n",
    "    summaries = infer.generate_summary(text, model, tokenizer, TRAIN_ARGS[\"ENCODER_LENGTH\"], TRAIN_ARGS[\"DECODER_LENGTH\"])\n",
    "    \n",
    "    \n",
    "    set_df[\"epoch_set\"] = epoch_set\n",
    "    set_df[\"prediction\"] = summaries[1]\n",
    "    set_df[\"rouge\"] = rouge.compute(predictions=set_df[\"prediction\"], \n",
    "                references=set_df[\"output_sequence\"],\n",
    "                use_stemmer=True, \n",
    "                use_aggregator=False,\n",
    "                rouge_types=[\"rouge1\"])[\"rouge1\"]\n",
    "\n",
    "    if epoch_set==0:\n",
    "        test_result_df = set_df.copy()\n",
    "    else: \n",
    "        test_result_df = pd.concat([test_result_df, set_df])\n",
    "\n",
    "\n",
    "    \n",
    "    ########## SAVE EPOCH SET MODEL\n",
    "    if not os.path.exists(MODEL_PATH): \n",
    "        os.mkdir(MODEL_PATH)\n",
    "\n",
    "    trainer.save_model(MODEL_PATH)\n",
    "\n",
    "    latest_run_epoch = epoch_set\n",
    "\n",
    "\n",
    "########## SAVE THE FILE\n",
    "\n",
    "with open('test_results_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_result_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "epoch_set\n",
      "0     0.099899\n",
      "1     0.240821\n",
      "2     0.256972\n",
      "3     0.256961\n",
      "4     0.253691\n",
      "8     0.260204\n",
      "10    0.255541\n",
      "16    0.254826\n",
      "Name: rouge, dtype: float64\n",
      "STD\n",
      "epoch_set\n",
      "0     0.117489\n",
      "1     0.155287\n",
      "2     0.156484\n",
      "3     0.157056\n",
      "4     0.158867\n",
      "8     0.157606\n",
      "10    0.159483\n",
      "16    0.157675\n",
      "Name: rouge, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "########## ROUGE PER SETTING\n",
    "\n",
    "print(\"Mean\")\n",
    "print(test_result_df.groupby(\"epoch_set\")[\"rouge\"].mean())\n",
    "\n",
    "print(\"STD\")\n",
    "print(test_result_df.groupby(\"epoch_set\")[\"rouge\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2597654216346624"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ENSEMBLE COMPUTE\n",
    "test_result_df[\"opt_es_id\"] = test_result_df.id.map(optimal_ensemble_map)\n",
    "ensemble_preds = test_result_df.loc[test_result_df[\"epoch_set\"]==test_result_df[\"opt_es_id\"], :]\n",
    "ensemble_preds[\"rouge\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opt_es_id\n",
       "8     13224\n",
       "16      424\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df.opt_es_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
